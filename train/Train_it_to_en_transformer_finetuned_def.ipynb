{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vSUyCs23M_H2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687697103104,"user_tz":-120,"elapsed":3754,"user":{"displayName":"Manuel Dellabona","userId":"00334919419808458942"}},"outputId":"8e7e7bf2-c2d3-4b8f-aafe-88c91853fde4"},"source":["# Install OpenNMT-py 3.x\n","!pip3 install OpenNMT-py"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: OpenNMT-py in /usr/local/lib/python3.10/dist-packages (3.3)\n","Requirement already satisfied: torch<2.1,>=1.13 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.0.1+cu118)\n","Requirement already satisfied: configargparse in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (1.5.3)\n","Requirement already satisfied: ctranslate2<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (3.16.0)\n","Requirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.12.3)\n","Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.2.5)\n","Requirement already satisfied: waitress in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.1.2)\n","Requirement already satisfied: pyonmttok<2,>=1.35 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (1.37.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (6.0)\n","Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.3.1)\n","Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (3.1.1)\n","Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.0.0)\n","Requirement already satisfied: fasttext-wheel in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (0.9.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.2->OpenNMT-py) (1.22.4)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.54.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.4.3)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.27.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.3.6)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.40.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.13->OpenNMT-py) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.13->OpenNMT-py) (4.6.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.13->OpenNMT-py) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.13->OpenNMT-py) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.13->OpenNMT-py) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.13->OpenNMT-py) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=1.13->OpenNMT-py) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=1.13->OpenNMT-py) (16.0.6)\n","Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel->OpenNMT-py) (2.10.4)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (8.1.3)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (2.7.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (2022.10.31)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (0.8.10)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (0.4.6)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (4.9.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.3->OpenNMT-py) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.1,>=1.13->OpenNMT-py) (2.1.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.1,>=1.13->OpenNMT-py) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.3->OpenNMT-py) (3.2.2)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_q0jwgQwLdYT","executionInfo":{"status":"ok","timestamp":1687697108019,"user_tz":-120,"elapsed":2027,"user":{"displayName":"Manuel Dellabona","userId":"00334919419808458942"}},"outputId":"ee9507a1-4dc7-470d-f886-f683b799a91c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"dWVOWYedzZ_G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687697120701,"user_tz":-120,"elapsed":601,"user":{"displayName":"Manuel Dellabona","userId":"00334919419808458942"}},"outputId":"398a386a-2690-4471-eb49-0f3bbacb5783"},"source":["# Open the folder where you saved your prepapred datasets from the first exercise\n","# You might need to mount your Google Drive first\n","%cd /content/drive/MyDrive/NLP2/fine_tuned/it_to_en/nmt/\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/15ST_GbtQNVxa6lxoGBZxd99QBIwzy53D/NLP2/fine_tuned/it_to_en/nmt\n","compute-bleu.py\n","compute-bleu.py.1\n","config_brnn.yaml\n","config_trans.yaml\n","config.yaml\n","Europarl.en-it.en\n","Europarl.en-it.en-filtered.en\n","Europarl.en-it.en-filtered.en.subword\n","Europarl.en-it.en-filtered.en.subword.dev\n","Europarl.en-it.en-filtered.en.subword.test\n","Europarl.en-it.en-filtered.en.subword.test.desubword\n","Europarl.en-it.en-filtered.en.subword.train\n","Europarl.en-it.it\n","Europarl.en-it.it-filtered.it\n","Europarl.en-it.it-filtered.it.subword\n","Europarl.en-it.it-filtered.it.subword.dev\n","Europarl.en-it.it-filtered.it.subword.test\n","Europarl.en-it.it-filtered.it.subword.train\n","Europarl.en-it.xml\n","Europarl.en.translated\n","Europarl.en.translated2\n","Europarl.en.translated2.desubword\n","Europarl.en.translated.desubword\n","LICENSE\n","models\n","models_1l\n","models_2l\n","models_lstm\n","MT-Preparation\n","README\n","run\n","source.model\n","source.vocab\n","target.model\n","target.vocab\n","train.log\n"]}]},{"cell_type":"code","metadata":{"id":"qbW7Xek6UDlY"},"source":["# TRANSFORMER\n","\n","config_trans = '''# config_trans.yaml\n","\n","\n","## Where the samples will be written\n","save_data: run\n","\n","# Training files\n","data:\n","    corpus_1:\n","        path_src: Europarl.en-it.it-filtered.it.subword.train\n","        path_tgt: Europarl.en-it.en-filtered.en.subword.train\n","        transforms: [filtertoolong]\n","    valid:\n","        path_src: Europarl.en-it.it-filtered.it.subword.dev\n","        path_tgt: Europarl.en-it.en-filtered.en.subword.dev\n","        transforms: [filtertoolong]\n","\n","# Vocabulary files, generated by onmt_build_vocab\n","src_vocab: run/source.vocab\n","tgt_vocab: run/target.vocab\n","\n","# Vocabulary size - should be the same as in sentence piece\n","src_vocab_size: 50000\n","tgt_vocab_size: 50000\n","\n","# Filter out source/target longer than n if [filtertoolong] enabled\n","src_seq_length: 150\n","src_seq_length: 150\n","\n","# Tokenization options\n","src_subword_model: source.model\n","tgt_subword_model: target.model\n","\n","# Where to save the log file and the output models/checkpoints\n","log_file: train.log\n","save_model: models/model.fren\n","\n","# Stop training if it does not imporve after n validations\n","early_stopping: 3\n","\n","# Default: 5000 - Save a model checkpoint for each n\n","save_checkpoint_steps: 5000\n","\n","# To save space, limit checkpoints to last n\n","# keep_checkpoint: 3\n","\n","seed: 3435\n","\n","# Default: 100000 - Train the model to max n steps\n","# Increase to 200000 or more for large datasets\n","# For fine-tuning, add up the required steps to the original steps\n","train_steps: 25000\n","\n","# Default: 10000 - Run validation after n steps\n","valid_steps: 500\n","\n","# Default: 4000 - for large datasets, try up to 8000\n","warmup_steps: 2000\n","report_every: 100\n","\n","# Number of GPUs, and IDs of GPUs\n","world_size: 1\n","gpu_ranks: [0]\n","\n","# Batching\n","bucket_size: 262144\n","num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n","batch_type: \"tokens\"\n","batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n","valid_batch_size: 2048\n","max_generator_batches: 2\n","accum_count: [4]\n","accum_steps: [0]\n","\n","# Optimization\n","model_dtype: \"fp16\"\n","optim: \"adam\"\n","learning_rate: 3\n","# warmup_steps: 8000\n","decay_method: \"noam\"\n","adam_beta2: 0.998\n","max_grad_norm: 0\n","label_smoothing: 0.1\n","param_init: 0\n","param_init_glorot: true\n","normalization: \"tokens\"\n","\n","# Model\n","encoder_type: transformer\n","decoder_type: transformer\n","position_encoding: true\n","enc_layers: 2\n","dec_layers: 2\n","heads: 8\n","hidden_size: 1024\n","word_vec_size: 1024\n","transformer_ff: 2048\n","dropout_steps: [0]\n","dropout: [0.1]\n","attention_dropout: [0.1]\n","'''\n","\n","with open(\"config_trans.yaml\", \"w+\") as config_trans_yaml:\n","  config_trans_yaml.write(config_trans)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AuwltKp_VhnQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687697137549,"user_tz":-120,"elapsed":417,"user":{"displayName":"Manuel Dellabona","userId":"00334919419808458942"}},"outputId":"99641f73-6a77-43d2-c99a-9f469cc2e756"},"source":["# Find the number of CPUs/cores on the machine\n","!nproc --all"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n"]}]},{"cell_type":"code","metadata":{"id":"P2GV1PgyUsJr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687697193860,"user_tz":-120,"elapsed":54095,"user":{"displayName":"Manuel Dellabona","userId":"00334919419808458942"}},"outputId":"4852658f-ac3e-427d-a3a4-db1b94b97ec2"},"source":["# Build Vocabulary\n","\n","# -config: path to your config.yaml file\n","# -n_sample: use -1 to build vocabulary on all the segment in the training dataset\n","# -num_threads: change it to match the number of CPUs to run it faster\n","\n","!onmt_build_vocab -config config_trans.yaml -n_sample -1 -num_threads 4"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2023-06-25 12:45:41,348 INFO] Counter vocab from -1 samples.\n","[2023-06-25 12:45:41,348 INFO] n_sample=-1: Build vocab on full datasets.\n","[2023-06-25 12:46:32,007 INFO] * Transform statistics for corpus_1(25.00%):\n","\t\t\t* FilterTooLongStats(filtered=253)\n","\n","[2023-06-25 12:46:32,212 INFO] * Transform statistics for corpus_1(25.00%):\n","\t\t\t* FilterTooLongStats(filtered=238)\n","\n","[2023-06-25 12:46:32,339 INFO] * Transform statistics for corpus_1(25.00%):\n","\t\t\t* FilterTooLongStats(filtered=247)\n","\n","[2023-06-25 12:46:32,819 INFO] * Transform statistics for corpus_1(25.00%):\n","\t\t\t* FilterTooLongStats(filtered=260)\n","\n","[2023-06-25 12:46:33,009 INFO] Counters src: 49429\n","[2023-06-25 12:46:33,009 INFO] Counters tgt: 48187\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/onmt_build_vocab\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/bin/build_vocab.py\", line 283, in main\n","    build_vocab_main(opts)\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/bin/build_vocab.py\", line 267, in build_vocab_main\n","    save_counter(src_counter, opts.src_vocab)\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/bin/build_vocab.py\", line 256, in save_counter\n","    check_path(save_path, exist_ok=opts.overwrite, log=logger.warning)\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/utils/misc.py\", line 47, in check_path\n","    raise IOError(f\"path {path} exists, stop.\")\n","OSError: path run/source.vocab exists, stop.\n"]}]},{"cell_type":"code","metadata":{"id":"TMMPeS-pSV8I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687697193860,"user_tz":-120,"elapsed":9,"user":{"displayName":"Manuel Dellabona","userId":"00334919419808458942"}},"outputId":"421f16f4-512c-4c9b-ee22-139bd28ebfea"},"source":["# Check if the GPU is active\n","!nvidia-smi -L"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla T4 (UUID: GPU-b6337c55-9052-ea3d-c9f3-86bce32541d3)\n"]}]},{"cell_type":"code","metadata":{"id":"_3rVQhd4NXNG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687697195532,"user_tz":-120,"elapsed":1675,"user":{"displayName":"Manuel Dellabona","userId":"00334919419808458942"}},"outputId":"3db720d8-8430-466d-eb81-999518c0bbb9"},"source":["# Check if the GPU is visable to PyTorch\n","\n","import torch\n","\n","print(torch.cuda.is_available())\n","print(torch.cuda.get_device_name(0))\n","\n","gpu_memory = torch.cuda.mem_get_info(0)\n","print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","Tesla T4\n","Free GPU memory: 14998.8125 out of: 15101.8125\n"]}]},{"cell_type":"code","metadata":{"id":"prJCKA2CP-dl","colab":{"base_uri":"https://localhost:8080/"},"outputId":"027d5b27-64d7-4c3f-f6a1-16604b1ba7d1","executionInfo":{"status":"ok","timestamp":1687619962036,"user_tz":-120,"elapsed":1067299,"user":{"displayName":"Manuel Dellabona","userId":"00334919419808458942"}}},"source":["# Train the NMT model\n","# train 2 layer 512 hidden size\n","!onmt_train -config config_trans.yaml"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2023-06-24 15:01:36,385 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2023-06-24 15:01:37,033 INFO] Parsed 2 corpora from -data.\n","[2023-06-24 15:01:37,034 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n","[2023-06-24 15:01:38,044 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', ',', '▁di', '.', \"'\", '▁e', '▁che']\n","[2023-06-24 15:01:38,045 INFO] The decoder start token is: <s>\n","[2023-06-24 15:01:38,045 INFO] Building model...\n","[2023-06-24 15:01:39,363 INFO] Switching model to float32 for amp/apex_amp\n","[2023-06-24 15:01:39,363 INFO] Non quantized layer compute is fp16\n","[2023-06-24 15:01:39,559 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(49440, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): ModuleList(\n","      (0-1): 2 x TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(48192, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","    (transformer_layers): ModuleList(\n","      (0-1): 2 x TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n","        )\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (generator): Linear(in_features=512, out_features=48192, bias=True)\n",")\n","[2023-06-24 15:01:39,561 INFO] encoder: 31609856\n","[2023-06-24 15:01:39,561 INFO] decoder: 57792576\n","[2023-06-24 15:01:39,561 INFO] * number of parameters: 89402432\n","[2023-06-24 15:01:39,562 INFO] Trainable parameters = {'torch.float32': 89402432, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2023-06-24 15:01:39,562 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2023-06-24 15:01:39,562 INFO]  * src vocab size = 49440\n","[2023-06-24 15:01:39,562 INFO]  * tgt vocab size = 48192\n","[2023-06-24 15:01:39,566 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 1\n","[2023-06-24 15:01:39,567 INFO] Starting training on GPU: [0]\n","[2023-06-24 15:01:39,567 INFO] Start training loop and validate every 500 steps...\n","[2023-06-24 15:01:39,567 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=150, tgt_seq_length=192))\n","[2023-06-24 15:02:20,883 INFO] Step 100/ 5000; acc: 5.2; ppl: 15283.3; xent: 9.6; lr: 0.00010; sents:   47882; bsz: 3737/3798/120; 36180/36773 tok/s;     41 sec;\n","[2023-06-24 15:02:34,140 INFO] Step 200/ 5000; acc: 10.2; ppl: 1244.8; xent: 7.1; lr: 0.00020; sents:   47368; bsz: 3737/3802/118; 112755/114712 tok/s;     55 sec;\n","[2023-06-24 15:02:47,189 INFO] Step 300/ 5000; acc: 20.8; ppl: 491.6; xent: 6.2; lr: 0.00030; sents:   47686; bsz: 3732/3799/119; 114398/116448 tok/s;     68 sec;\n","[2023-06-24 15:03:00,325 INFO] Step 400/ 5000; acc: 27.0; ppl: 268.8; xent: 5.6; lr: 0.00040; sents:   49292; bsz: 3720/3792/123; 113270/115457 tok/s;     81 sec;\n","[2023-06-24 15:03:13,367 INFO] Step 500/ 5000; acc: 33.8; ppl: 163.3; xent: 5.1; lr: 0.00050; sents:   48366; bsz: 3734/3804/121; 114515/116663 tok/s;     94 sec;\n","[2023-06-24 15:03:16,044 INFO] valid stats calculation and sentences rebuilding\n","                           took: 2.6758782863616943 s.\n","[2023-06-24 15:03:16,044 INFO] Train perplexity: 836.856\n","[2023-06-24 15:03:16,044 INFO] Train accuracy: 19.4125\n","[2023-06-24 15:03:16,044 INFO] Sentences processed: 240594\n","[2023-06-24 15:03:16,044 INFO] Average bsz: 3732/3799/120\n","[2023-06-24 15:03:16,044 INFO] Validation perplexity: 115.688\n","[2023-06-24 15:03:16,044 INFO] Validation accuracy: 39.1018\n","[2023-06-24 15:03:16,044 INFO] Model is improving ppl: inf --> 115.688.\n","[2023-06-24 15:03:16,044 INFO] Model is improving acc: -inf --> 39.1018.\n","[2023-06-24 15:04:04,120 INFO] Step 600/ 5000; acc: 40.8; ppl: 100.9; xent: 4.6; lr: 0.00059; sents:   49694; bsz: 3728/3797/124; 29385/29929 tok/s;    145 sec;\n","[2023-06-24 15:04:18,209 INFO] Step 700/ 5000; acc: 46.1; ppl:  70.0; xent: 4.2; lr: 0.00069; sents:   49022; bsz: 3730/3799/123; 105897/107872 tok/s;    159 sec;\n","[2023-06-24 15:04:32,312 INFO] Step 800/ 5000; acc: 49.5; ppl:  54.4; xent: 4.0; lr: 0.00079; sents:   50093; bsz: 3726/3797/125; 105692/107691 tok/s;    173 sec;\n","[2023-06-24 15:04:46,338 INFO] Step 900/ 5000; acc: 51.9; ppl:  45.8; xent: 3.8; lr: 0.00089; sents:   48346; bsz: 3730/3798/121; 106367/108320 tok/s;    187 sec;\n","[2023-06-24 15:05:00,322 INFO] Step 1000/ 5000; acc: 53.3; ppl:  41.0; xent: 3.7; lr: 0.00099; sents:   46359; bsz: 3737/3804/116; 106888/108823 tok/s;    201 sec;\n","[2023-06-24 15:05:00,514 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-24 15:05:02,351 INFO] valid stats calculation and sentences rebuilding\n","                           took: 2.028820037841797 s.\n","[2023-06-24 15:05:02,353 INFO] Train perplexity: 222.378\n","[2023-06-24 15:05:02,353 INFO] Train accuracy: 33.8608\n","[2023-06-24 15:05:02,353 INFO] Sentences processed: 484108\n","[2023-06-24 15:05:02,353 INFO] Average bsz: 3731/3799/121\n","[2023-06-24 15:05:02,353 INFO] Validation perplexity: 34.3787\n","[2023-06-24 15:05:02,353 INFO] Validation accuracy: 56.4542\n","[2023-06-24 15:05:02,353 INFO] Model is improving ppl: 115.688 --> 34.3787.\n","[2023-06-24 15:05:02,353 INFO] Model is improving acc: 39.1018 --> 56.4542.\n","[2023-06-24 15:05:52,199 INFO] Step 1100/ 5000; acc: 54.4; ppl:  37.7; xent: 3.6; lr: 0.00109; sents:   47237; bsz: 3736/3801/118; 28804/29310 tok/s;    253 sec;\n","[2023-06-24 15:06:06,196 INFO] Step 1200/ 5000; acc: 55.4; ppl:  35.2; xent: 3.6; lr: 0.00119; sents:   48904; bsz: 3728/3797/122; 106533/108500 tok/s;    267 sec;\n","[2023-06-24 15:06:20,066 INFO] Step 1300/ 5000; acc: 56.0; ppl:  33.5; xent: 3.5; lr: 0.00129; sents:   49244; bsz: 3729/3797/123; 107565/109517 tok/s;    280 sec;\n","[2023-06-24 15:06:33,838 INFO] Step 1400/ 5000; acc: 56.6; ppl:  32.2; xent: 3.5; lr: 0.00138; sents:   48245; bsz: 3728/3795/121; 108286/110221 tok/s;    294 sec;\n","[2023-06-24 15:06:47,725 INFO] Step 1500/ 5000; acc: 57.0; ppl:  31.1; xent: 3.4; lr: 0.00148; sents:   48642; bsz: 3736/3801/122; 107618/109483 tok/s;    308 sec;\n","[2023-06-24 15:06:47,903 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-24 15:06:49,787 INFO] valid stats calculation and sentences rebuilding\n","                           took: 2.061589479446411 s.\n","[2023-06-24 15:06:49,788 INFO] Train perplexity: 118.751\n","[2023-06-24 15:06:49,788 INFO] Train accuracy: 41.1983\n","[2023-06-24 15:06:49,788 INFO] Sentences processed: 726380\n","[2023-06-24 15:06:49,788 INFO] Average bsz: 3731/3799/121\n","[2023-06-24 15:06:49,788 INFO] Validation perplexity: 27.3729\n","[2023-06-24 15:06:49,788 INFO] Validation accuracy: 59.7782\n","[2023-06-24 15:06:49,788 INFO] Model is improving ppl: 34.3787 --> 27.3729.\n","[2023-06-24 15:06:49,788 INFO] Model is improving acc: 56.4542 --> 59.7782.\n","[2023-06-24 15:07:03,890 INFO] Step 1600/ 5000; acc: 57.1; ppl:  30.9; xent: 3.4; lr: 0.00158; sents:   46840; bsz: 3735/3802/117; 92432/94086 tok/s;    324 sec;\n","[2023-06-24 15:07:51,041 INFO] Step 1700/ 5000; acc: 57.8; ppl:  29.7; xent: 3.4; lr: 0.00168; sents:   48353; bsz: 3735/3801/121; 31690/32246 tok/s;    371 sec;\n","[2023-06-24 15:08:04,841 INFO] Step 1800/ 5000; acc: 58.0; ppl:  29.0; xent: 3.4; lr: 0.00178; sents:   46670; bsz: 3739/3806/117; 108376/110315 tok/s;    385 sec;\n","[2023-06-24 15:08:18,852 INFO] Step 1900/ 5000; acc: 58.5; ppl:  28.1; xent: 3.3; lr: 0.00188; sents:   49948; bsz: 3729/3797/125; 106478/108404 tok/s;    399 sec;\n","[2023-06-24 15:08:32,743 INFO] Step 2000/ 5000; acc: 58.3; ppl:  28.4; xent: 3.3; lr: 0.00198; sents:   47756; bsz: 3729/3796/119; 107366/109314 tok/s;    413 sec;\n","[2023-06-24 15:08:32,913 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-24 15:08:34,795 INFO] valid stats calculation and sentences rebuilding\n","                           took: 2.051438093185425 s.\n","[2023-06-24 15:08:34,797 INFO] Train perplexity: 83.5997\n","[2023-06-24 15:08:34,797 INFO] Train accuracy: 45.3856\n","[2023-06-24 15:08:34,797 INFO] Sentences processed: 965947\n","[2023-06-24 15:08:34,797 INFO] Average bsz: 3732/3799/121\n","[2023-06-24 15:08:34,797 INFO] Validation perplexity: 24.7433\n","[2023-06-24 15:08:34,797 INFO] Validation accuracy: 60.971\n","[2023-06-24 15:08:34,797 INFO] Model is improving ppl: 27.3729 --> 24.7433.\n","[2023-06-24 15:08:34,797 INFO] Model is improving acc: 59.7782 --> 60.971.\n","[2023-06-24 15:08:48,658 INFO] Step 2100/ 5000; acc: 58.9; ppl:  27.3; xent: 3.3; lr: 0.00193; sents:   48356; bsz: 3734/3797/121; 93847/95441 tok/s;    429 sec;\n","[2023-06-24 15:09:39,599 INFO] Step 2200/ 5000; acc: 59.3; ppl:  26.5; xent: 3.3; lr: 0.00188; sents:   46175; bsz: 3744/3803/115; 29399/29865 tok/s;    480 sec;\n","[2023-06-24 15:09:53,567 INFO] Step 2300/ 5000; acc: 59.9; ppl:  25.5; xent: 3.2; lr: 0.00184; sents:   49378; bsz: 3729/3794/123; 106799/108652 tok/s;    494 sec;\n","[2023-06-24 15:10:07,547 INFO] Step 2400/ 5000; acc: 60.2; ppl:  25.0; xent: 3.2; lr: 0.00180; sents:   48450; bsz: 3733/3799/121; 106802/108688 tok/s;    508 sec;\n","[2023-06-24 15:10:21,294 INFO] Step 2500/ 5000; acc: 60.4; ppl:  24.5; xent: 3.2; lr: 0.00177; sents:   45387; bsz: 3746/3802/113; 108991/110643 tok/s;    522 sec;\n","[2023-06-24 15:10:21,488 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-24 15:10:23,298 INFO] valid stats calculation and sentences rebuilding\n","                           took: 2.0033798217773438 s.\n","[2023-06-24 15:10:23,299 INFO] Train perplexity: 66.052\n","[2023-06-24 15:10:23,299 INFO] Train accuracy: 48.2598\n","[2023-06-24 15:10:23,299 INFO] Sentences processed: 1.20369e+06\n","[2023-06-24 15:10:23,299 INFO] Average bsz: 3733/3799/120\n","[2023-06-24 15:10:23,299 INFO] Validation perplexity: 21.5099\n","[2023-06-24 15:10:23,299 INFO] Validation accuracy: 63.1187\n","[2023-06-24 15:10:23,299 INFO] Model is improving ppl: 24.7433 --> 21.5099.\n","[2023-06-24 15:10:23,299 INFO] Model is improving acc: 60.971 --> 63.1187.\n","[2023-06-24 15:10:36,906 INFO] Step 2600/ 5000; acc: 61.1; ppl:  23.6; xent: 3.2; lr: 0.00173; sents:   50529; bsz: 3720/3794/126; 95320/97223 tok/s;    537 sec;\n","[2023-06-24 15:10:50,648 INFO] Step 2700/ 5000; acc: 61.4; ppl:  23.1; xent: 3.1; lr: 0.00170; sents:   48911; bsz: 3729/3803/122; 108529/110693 tok/s;    551 sec;\n","[2023-06-24 15:11:40,781 INFO] Step 2800/ 5000; acc: 61.5; ppl:  22.9; xent: 3.1; lr: 0.00167; sents:   48975; bsz: 3733/3802/122; 29783/30336 tok/s;    601 sec;\n","[2023-06-24 15:11:54,188 INFO] Step 2900/ 5000; acc: 61.5; ppl:  22.8; xent: 3.1; lr: 0.00164; sents:   48245; bsz: 3731/3798/121; 111310/113309 tok/s;    615 sec;\n","[2023-06-24 15:12:07,751 INFO] Step 3000/ 5000; acc: 61.9; ppl:  22.3; xent: 3.1; lr: 0.00161; sents:   47215; bsz: 3736/3803/118; 110190/112173 tok/s;    628 sec;\n","[2023-06-24 15:12:07,947 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-24 15:12:09,758 INFO] valid stats calculation and sentences rebuilding\n","                           took: 2.006929636001587 s.\n","[2023-06-24 15:12:09,759 INFO] Train perplexity: 55.3786\n","[2023-06-24 15:12:09,760 INFO] Train accuracy: 50.4653\n","[2023-06-24 15:12:09,760 INFO] Sentences processed: 1.44757e+06\n","[2023-06-24 15:12:09,760 INFO] Average bsz: 3732/3799/121\n","[2023-06-24 15:12:09,760 INFO] Validation perplexity: 19.885\n","[2023-06-24 15:12:09,760 INFO] Validation accuracy: 64.2739\n","[2023-06-24 15:12:09,760 INFO] Model is improving ppl: 21.5099 --> 19.885.\n","[2023-06-24 15:12:09,760 INFO] Model is improving acc: 63.1187 --> 64.2739.\n","[2023-06-24 15:12:23,268 INFO] Step 3100/ 5000; acc: 61.9; ppl:  22.2; xent: 3.1; lr: 0.00159; sents:   46772; bsz: 3735/3803/117; 96290/98038 tok/s;    644 sec;\n","[2023-06-24 15:12:37,027 INFO] Step 3200/ 5000; acc: 62.2; ppl:  21.7; xent: 3.1; lr: 0.00156; sents:   48452; bsz: 3733/3798/121; 108530/110423 tok/s;    657 sec;\n","[2023-06-24 15:13:23,731 INFO] Step 3300/ 5000; acc: 62.6; ppl:  21.3; xent: 3.1; lr: 0.00154; sents:   50347; bsz: 3725/3794/126; 31902/32491 tok/s;    704 sec;\n","[2023-06-24 15:13:37,170 INFO] Step 3400/ 5000; acc: 62.6; ppl:  21.3; xent: 3.1; lr: 0.00152; sents:   47461; bsz: 3732/3800/119; 111083/113098 tok/s;    718 sec;\n","[2023-06-24 15:13:50,757 INFO] Step 3500/ 5000; acc: 62.8; ppl:  21.0; xent: 3.0; lr: 0.00149; sents:   50512; bsz: 3724/3794/126; 109640/111687 tok/s;    731 sec;\n","[2023-06-24 15:13:50,952 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-24 15:13:52,755 INFO] valid stats calculation and sentences rebuilding\n","                           took: 1.9973831176757812 s.\n","[2023-06-24 15:13:52,756 INFO] Train perplexity: 48.3852\n","[2023-06-24 15:13:52,756 INFO] Train accuracy: 52.1718\n","[2023-06-24 15:13:52,756 INFO] Sentences processed: 1.69111e+06\n","[2023-06-24 15:13:52,756 INFO] Average bsz: 3732/3799/121\n","[2023-06-24 15:13:52,756 INFO] Validation perplexity: 18.8309\n","[2023-06-24 15:13:52,756 INFO] Validation accuracy: 65.0454\n","[2023-06-24 15:13:52,756 INFO] Model is improving ppl: 19.885 --> 18.8309.\n","[2023-06-24 15:13:52,756 INFO] Model is improving acc: 64.2739 --> 65.0454.\n","[2023-06-24 15:14:06,232 INFO] Step 3600/ 5000; acc: 62.7; ppl:  21.0; xent: 3.0; lr: 0.00147; sents:   46948; bsz: 3734/3803/117; 96518/98301 tok/s;    747 sec;\n","[2023-06-24 15:14:20,145 INFO] Step 3700/ 5000; acc: 63.1; ppl:  20.6; xent: 3.0; lr: 0.00145; sents:   48050; bsz: 3737/3800/120; 107438/109266 tok/s;    761 sec;\n","[2023-06-24 15:14:35,671 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=974)\n","\n","[2023-06-24 15:14:35,671 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 2\n","[2023-06-24 15:15:12,127 INFO] Step 3800/ 5000; acc: 63.2; ppl:  20.5; xent: 3.0; lr: 0.00143; sents:   48696; bsz: 3732/3799/122; 28717/29230 tok/s;    813 sec;\n","[2023-06-24 15:15:26,181 INFO] Step 3900/ 5000; acc: 63.1; ppl:  20.5; xent: 3.0; lr: 0.00142; sents:   47346; bsz: 3731/3799/118; 106199/108115 tok/s;    827 sec;\n","[2023-06-24 15:15:40,184 INFO] Step 4000/ 5000; acc: 63.5; ppl:  20.1; xent: 3.0; lr: 0.00140; sents:   49470; bsz: 3729/3800/124; 106517/108552 tok/s;    841 sec;\n","[2023-06-24 15:15:40,347 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-24 15:15:42,173 INFO] valid stats calculation and sentences rebuilding\n","                           took: 1.988529920578003 s.\n","[2023-06-24 15:15:42,174 INFO] Train perplexity: 43.4659\n","[2023-06-24 15:15:42,174 INFO] Train accuracy: 53.539\n","[2023-06-24 15:15:42,174 INFO] Sentences processed: 1.93162e+06\n","[2023-06-24 15:15:42,174 INFO] Average bsz: 3732/3799/121\n","[2023-06-24 15:15:42,174 INFO] Validation perplexity: 18.0391\n","[2023-06-24 15:15:42,175 INFO] Validation accuracy: 65.6265\n","[2023-06-24 15:15:42,175 INFO] Model is improving ppl: 18.8309 --> 18.0391.\n","[2023-06-24 15:15:42,175 INFO] Model is improving acc: 65.0454 --> 65.6265.\n","[2023-06-24 15:15:56,187 INFO] Step 4100/ 5000; acc: 63.5; ppl:  20.0; xent: 3.0; lr: 0.00138; sents:   48359; bsz: 3734/3800/121; 93340/94983 tok/s;    857 sec;\n","[2023-06-24 15:16:10,062 INFO] Step 4200/ 5000; acc: 63.6; ppl:  19.8; xent: 3.0; lr: 0.00136; sents:   47814; bsz: 3731/3804/120; 107572/109670 tok/s;    870 sec;\n","[2023-06-24 15:16:23,902 INFO] Step 4300/ 5000; acc: 63.7; ppl:  19.7; xent: 3.0; lr: 0.00135; sents:   48232; bsz: 3735/3798/121; 107936/109769 tok/s;    884 sec;\n","[2023-06-24 15:17:12,450 INFO] Step 4400/ 5000; acc: 63.9; ppl:  19.5; xent: 3.0; lr: 0.00133; sents:   48095; bsz: 3733/3799/120; 30758/31305 tok/s;    933 sec;\n","[2023-06-24 15:17:26,302 INFO] Step 4500/ 5000; acc: 63.9; ppl:  19.4; xent: 3.0; lr: 0.00132; sents:   47869; bsz: 3723/3796/120; 107504/109615 tok/s;    947 sec;\n","[2023-06-24 15:17:26,503 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-24 15:17:28,355 INFO] valid stats calculation and sentences rebuilding\n","                           took: 2.051990270614624 s.\n","[2023-06-24 15:17:28,356 INFO] Train perplexity: 39.8042\n","[2023-06-24 15:17:28,356 INFO] Train accuracy: 54.6703\n","[2023-06-24 15:17:28,356 INFO] Sentences processed: 2.17199e+06\n","[2023-06-24 15:17:28,356 INFO] Average bsz: 3732/3799/121\n","[2023-06-24 15:17:28,356 INFO] Validation perplexity: 17.5223\n","[2023-06-24 15:17:28,356 INFO] Validation accuracy: 66.2461\n","[2023-06-24 15:17:28,356 INFO] Model is improving ppl: 18.0391 --> 17.5223.\n","[2023-06-24 15:17:28,356 INFO] Model is improving acc: 65.6265 --> 66.2461.\n","[2023-06-24 15:17:42,217 INFO] Step 4600/ 5000; acc: 63.9; ppl:  19.3; xent: 3.0; lr: 0.00130; sents:   48668; bsz: 3730/3798/122; 93754/95467 tok/s;    963 sec;\n","[2023-06-24 15:17:56,034 INFO] Step 4700/ 5000; acc: 64.3; ppl:  19.0; xent: 2.9; lr: 0.00129; sents:   48193; bsz: 3730/3800/120; 107990/110026 tok/s;    976 sec;\n","[2023-06-24 15:18:09,745 INFO] Step 4800/ 5000; acc: 64.2; ppl:  19.0; xent: 2.9; lr: 0.00128; sents:   48000; bsz: 3732/3799/120; 108880/110828 tok/s;    990 sec;\n","[2023-06-24 15:19:01,261 INFO] Step 4900/ 5000; acc: 64.6; ppl:  18.7; xent: 2.9; lr: 0.00126; sents:   48914; bsz: 3734/3801/122; 28990/29513 tok/s;   1042 sec;\n","[2023-06-24 15:19:14,957 INFO] Step 5000/ 5000; acc: 64.2; ppl:  18.9; xent: 2.9; lr: 0.00125; sents:   48001; bsz: 3733/3797/120; 109014/110902 tok/s;   1055 sec;\n","[2023-06-24 15:19:15,154 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-24 15:19:16,949 INFO] valid stats calculation and sentences rebuilding\n","                           took: 1.9913992881774902 s.\n","[2023-06-24 15:19:16,950 INFO] Train perplexity: 36.9653\n","[2023-06-24 15:19:16,950 INFO] Train accuracy: 55.627\n","[2023-06-24 15:19:16,951 INFO] Sentences processed: 2.41377e+06\n","[2023-06-24 15:19:16,951 INFO] Average bsz: 3732/3799/121\n","[2023-06-24 15:19:16,951 INFO] Validation perplexity: 16.925\n","[2023-06-24 15:19:16,951 INFO] Validation accuracy: 66.7646\n","[2023-06-24 15:19:16,951 INFO] Model is improving ppl: 17.5223 --> 16.925.\n","[2023-06-24 15:19:16,951 INFO] Model is improving acc: 66.2461 --> 66.7646.\n","[2023-06-24 15:19:16,966 INFO] Saving checkpoint models/model.fren_step_5000.pt\n"]}]},{"cell_type":"code","source":["# Train the NMT model\n","# train 3 layer 256 hidden size\n","!onmt_train -config config_trans.yaml"],"metadata":{"id":"3K-jxh5ZrRSk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687684737166,"user_tz":-120,"elapsed":2512635,"user":{"displayName":"Manuel Dellabona","userId":"00334919419808458942"}},"outputId":"2c602724-285d-49b5-f96a-2e7f46fb74a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2023-06-25 08:37:05,962 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2023-06-25 08:37:05,963 INFO] Parsed 2 corpora from -data.\n","[2023-06-25 08:37:05,963 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n","[2023-06-25 08:37:06,276 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', ',', '▁di', '.', \"'\", '▁e', '▁che']\n","[2023-06-25 08:37:06,277 INFO] The decoder start token is: <s>\n","[2023-06-25 08:37:06,277 INFO] Building model...\n","[2023-06-25 08:37:06,911 INFO] Switching model to float32 for amp/apex_amp\n","[2023-06-25 08:37:06,912 INFO] Non quantized layer compute is fp16\n","[2023-06-25 08:37:07,147 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(49440, 256, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): ModuleList(\n","      (0-2): 3 x TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_values): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_query): Linear(in_features=256, out_features=256, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=256, out_features=256, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=256, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=256, bias=False)\n","          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(48192, 256, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","    (transformer_layers): ModuleList(\n","      (0-2): 3 x TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_values): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_query): Linear(in_features=256, out_features=256, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=256, out_features=256, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=256, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=256, bias=False)\n","          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_values): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_query): Linear(in_features=256, out_features=256, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=256, out_features=256, bias=False)\n","        )\n","        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (generator): Linear(in_features=256, out_features=48192, bias=True)\n",")\n","[2023-06-25 08:37:07,149 INFO] encoder: 16592384\n","[2023-06-25 08:37:07,149 INFO] decoder: 29446208\n","[2023-06-25 08:37:07,149 INFO] * number of parameters: 46038592\n","[2023-06-25 08:37:07,150 INFO] Trainable parameters = {'torch.float32': 46038592, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2023-06-25 08:37:07,150 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2023-06-25 08:37:07,150 INFO]  * src vocab size = 49440\n","[2023-06-25 08:37:07,150 INFO]  * tgt vocab size = 48192\n","[2023-06-25 08:37:07,153 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 1\n","[2023-06-25 08:37:07,153 INFO] Starting training on GPU: [0]\n","[2023-06-25 08:37:07,153 INFO] Start training loop and validate every 500 steps...\n","[2023-06-25 08:37:07,154 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=150, tgt_seq_length=192))\n","[2023-06-25 08:38:15,087 INFO] Step 100/ 5000; acc: 5.0; ppl: 20933.1; xent: 9.9; lr: 0.00014; sents:   47882; bsz: 3737/3798/120; 22004/22365 tok/s;     68 sec;\n","[2023-06-25 08:38:57,541 INFO] Step 200/ 5000; acc: 7.3; ppl: 1778.9; xent: 7.5; lr: 0.00028; sents:   47368; bsz: 3737/3802/118; 35210/35821 tok/s;    110 sec;\n","[2023-06-25 08:39:39,751 INFO] Step 300/ 5000; acc: 16.1; ppl: 718.3; xent: 6.6; lr: 0.00042; sents:   47686; bsz: 3732/3799/119; 35365/35999 tok/s;    153 sec;\n","[2023-06-25 08:40:21,973 INFO] Step 400/ 5000; acc: 22.8; ppl: 366.2; xent: 5.9; lr: 0.00056; sents:   49292; bsz: 3720/3792/123; 35241/35921 tok/s;    195 sec;\n","[2023-06-25 08:41:04,200 INFO] Step 500/ 5000; acc: 26.8; ppl: 253.9; xent: 5.5; lr: 0.00070; sents:   48366; bsz: 3734/3804/121; 35368/36032 tok/s;    237 sec;\n","[2023-06-25 08:41:09,133 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.933083772659302 s.\n","[2023-06-25 08:41:09,134 INFO] Train perplexity: 1199.91\n","[2023-06-25 08:41:09,135 INFO] Train accuracy: 15.6062\n","[2023-06-25 08:41:09,135 INFO] Sentences processed: 240594\n","[2023-06-25 08:41:09,135 INFO] Average bsz: 3732/3799/120\n","[2023-06-25 08:41:09,135 INFO] Validation perplexity: 202.334\n","[2023-06-25 08:41:09,135 INFO] Validation accuracy: 29.7532\n","[2023-06-25 08:41:09,135 INFO] Model is improving ppl: inf --> 202.334.\n","[2023-06-25 08:41:09,135 INFO] Model is improving acc: -inf --> 29.7532.\n","[2023-06-25 08:42:24,802 INFO] Step 600/ 5000; acc: 31.4; ppl: 179.5; xent: 5.2; lr: 0.00084; sents:   49694; bsz: 3728/3797/124; 18503/18845 tok/s;    318 sec;\n","[2023-06-25 08:43:07,418 INFO] Step 700/ 5000; acc: 36.5; ppl: 128.2; xent: 4.9; lr: 0.00098; sents:   49022; bsz: 3730/3799/123; 35009/35662 tok/s;    360 sec;\n","[2023-06-25 08:43:49,965 INFO] Step 800/ 5000; acc: 41.2; ppl:  93.0; xent: 4.5; lr: 0.00112; sents:   50093; bsz: 3726/3797/125; 35032/35695 tok/s;    403 sec;\n","[2023-06-25 08:44:32,423 INFO] Step 900/ 5000; acc: 44.9; ppl:  72.0; xent: 4.3; lr: 0.00126; sents:   48346; bsz: 3730/3798/121; 35139/35785 tok/s;    445 sec;\n","[2023-06-25 08:45:14,941 INFO] Step 1000/ 5000; acc: 47.7; ppl:  58.7; xent: 4.1; lr: 0.00140; sents:   46359; bsz: 3737/3804/116; 35153/35789 tok/s;    488 sec;\n","[2023-06-25 08:45:15,117 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 08:45:18,743 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.801147937774658 s.\n","[2023-06-25 08:45:18,744 INFO] Train perplexity: 342.887\n","[2023-06-25 08:45:18,744 INFO] Train accuracy: 27.9779\n","[2023-06-25 08:45:18,744 INFO] Sentences processed: 484108\n","[2023-06-25 08:45:18,744 INFO] Average bsz: 3731/3799/121\n","[2023-06-25 08:45:18,744 INFO] Validation perplexity: 46.955\n","[2023-06-25 08:45:18,744 INFO] Validation accuracy: 51.6444\n","[2023-06-25 08:45:18,745 INFO] Model is improving ppl: 202.334 --> 46.955.\n","[2023-06-25 08:45:18,745 INFO] Model is improving acc: 29.7532 --> 51.6444.\n","[2023-06-25 08:46:35,593 INFO] Step 1100/ 5000; acc: 49.8; ppl:  50.8; xent: 3.9; lr: 0.00154; sents:   47237; bsz: 3736/3801/118; 18527/18852 tok/s;    568 sec;\n","[2023-06-25 08:47:18,383 INFO] Step 1200/ 5000; acc: 51.7; ppl:  44.6; xent: 3.8; lr: 0.00168; sents:   48904; bsz: 3728/3797/122; 34849/35493 tok/s;    611 sec;\n","[2023-06-25 08:48:00,942 INFO] Step 1300/ 5000; acc: 52.9; ppl:  40.9; xent: 3.7; lr: 0.00182; sents:   49244; bsz: 3729/3797/123; 35053/35689 tok/s;    654 sec;\n","[2023-06-25 08:48:43,697 INFO] Step 1400/ 5000; acc: 54.0; ppl:  37.8; xent: 3.6; lr: 0.00196; sents:   48245; bsz: 3728/3795/121; 34880/35503 tok/s;    697 sec;\n","[2023-06-25 08:49:26,430 INFO] Step 1500/ 5000; acc: 54.8; ppl:  35.9; xent: 3.6; lr: 0.00210; sents:   48642; bsz: 3736/3801/122; 34973/35579 tok/s;    739 sec;\n","[2023-06-25 08:49:26,614 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 08:49:30,278 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.8468050956726074 s.\n","[2023-06-25 08:49:30,278 INFO] Train perplexity: 169.882\n","[2023-06-25 08:49:30,279 INFO] Train accuracy: 36.1934\n","[2023-06-25 08:49:30,279 INFO] Sentences processed: 726380\n","[2023-06-25 08:49:30,279 INFO] Average bsz: 3731/3799/121\n","[2023-06-25 08:49:30,279 INFO] Validation perplexity: 30.2273\n","[2023-06-25 08:49:30,279 INFO] Validation accuracy: 58.1553\n","[2023-06-25 08:49:30,279 INFO] Model is improving ppl: 46.955 --> 30.2273.\n","[2023-06-25 08:49:30,279 INFO] Model is improving acc: 51.6444 --> 58.1553.\n","[2023-06-25 08:50:12,980 INFO] Step 1600/ 5000; acc: 55.2; ppl:  34.8; xent: 3.6; lr: 0.00224; sents:   46840; bsz: 3735/3802/117; 32098/32672 tok/s;    786 sec;\n","[2023-06-25 08:51:27,782 INFO] Step 1700/ 5000; acc: 56.1; ppl:  32.9; xent: 3.5; lr: 0.00238; sents:   48353; bsz: 3735/3801/121; 19976/20326 tok/s;    861 sec;\n","[2023-06-25 08:52:10,442 INFO] Step 1800/ 5000; acc: 56.6; ppl:  31.7; xent: 3.5; lr: 0.00252; sents:   46670; bsz: 3739/3806/117; 35059/35686 tok/s;    903 sec;\n","[2023-06-25 08:52:53,021 INFO] Step 1900/ 5000; acc: 57.1; ppl:  30.7; xent: 3.4; lr: 0.00266; sents:   49948; bsz: 3729/3797/125; 35036/35670 tok/s;    946 sec;\n","[2023-06-25 08:53:35,685 INFO] Step 2000/ 5000; acc: 57.1; ppl:  30.5; xent: 3.4; lr: 0.00279; sents:   47756; bsz: 3729/3796/119; 34957/35591 tok/s;    989 sec;\n","[2023-06-25 08:53:35,854 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 08:53:39,532 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.8453967571258545 s.\n","[2023-06-25 08:53:39,533 INFO] Train perplexity: 111.98\n","[2023-06-25 08:53:39,533 INFO] Train accuracy: 41.2529\n","[2023-06-25 08:53:39,533 INFO] Sentences processed: 965947\n","[2023-06-25 08:53:39,533 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 08:53:39,533 INFO] Validation perplexity: 25.8876\n","[2023-06-25 08:53:39,533 INFO] Validation accuracy: 60.144\n","[2023-06-25 08:53:39,533 INFO] Model is improving ppl: 30.2273 --> 25.8876.\n","[2023-06-25 08:53:39,533 INFO] Model is improving acc: 58.1553 --> 60.144.\n","[2023-06-25 08:54:22,122 INFO] Step 2100/ 5000; acc: 57.9; ppl:  29.1; xent: 3.4; lr: 0.00273; sents:   48356; bsz: 3734/3797/121; 32163/32710 tok/s;   1035 sec;\n","[2023-06-25 08:55:39,742 INFO] Step 2200/ 5000; acc: 58.3; ppl:  28.3; xent: 3.3; lr: 0.00266; sents:   46175; bsz: 3744/3803/115; 19294/19600 tok/s;   1113 sec;\n","[2023-06-25 08:56:22,526 INFO] Step 2300/ 5000; acc: 58.9; ppl:  27.2; xent: 3.3; lr: 0.00261; sents:   49378; bsz: 3729/3794/123; 34866/35470 tok/s;   1155 sec;\n","[2023-06-25 08:57:04,985 INFO] Step 2400/ 5000; acc: 59.3; ppl:  26.6; xent: 3.3; lr: 0.00255; sents:   48450; bsz: 3733/3799/121; 35167/35788 tok/s;   1198 sec;\n","[2023-06-25 08:57:47,709 INFO] Step 2500/ 5000; acc: 59.4; ppl:  26.1; xent: 3.3; lr: 0.00250; sents:   45387; bsz: 3746/3802/113; 35067/35599 tok/s;   1241 sec;\n","[2023-06-25 08:57:47,881 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 08:57:51,554 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.8440515995025635 s.\n","[2023-06-25 08:57:51,555 INFO] Train perplexity: 84.53\n","[2023-06-25 08:57:51,555 INFO] Train accuracy: 44.7547\n","[2023-06-25 08:57:51,555 INFO] Sentences processed: 1.20369e+06\n","[2023-06-25 08:57:51,555 INFO] Average bsz: 3733/3799/120\n","[2023-06-25 08:57:51,555 INFO] Validation perplexity: 22.2544\n","[2023-06-25 08:57:51,556 INFO] Validation accuracy: 62.4059\n","[2023-06-25 08:57:51,556 INFO] Model is improving ppl: 25.8876 --> 22.2544.\n","[2023-06-25 08:57:51,556 INFO] Model is improving acc: 60.144 --> 62.4059.\n","[2023-06-25 08:58:34,025 INFO] Step 2600/ 5000; acc: 60.2; ppl:  25.0; xent: 3.2; lr: 0.00245; sents:   50529; bsz: 3720/3794/126; 32129/32771 tok/s;   1287 sec;\n","[2023-06-25 08:59:16,535 INFO] Step 2700/ 5000; acc: 60.5; ppl:  24.6; xent: 3.2; lr: 0.00241; sents:   48911; bsz: 3729/3803/122; 35084/35784 tok/s;   1329 sec;\n","[2023-06-25 09:00:34,813 INFO] Step 2800/ 5000; acc: 60.5; ppl:  24.3; xent: 3.2; lr: 0.00236; sents:   48975; bsz: 3733/3802/122; 19074/19428 tok/s;   1408 sec;\n","[2023-06-25 09:01:17,312 INFO] Step 2900/ 5000; acc: 60.6; ppl:  24.2; xent: 3.2; lr: 0.00232; sents:   48245; bsz: 3731/3798/121; 35113/35744 tok/s;   1450 sec;\n","[2023-06-25 09:01:59,881 INFO] Step 3000/ 5000; acc: 61.1; ppl:  23.6; xent: 3.2; lr: 0.00228; sents:   47215; bsz: 3736/3803/118; 35107/35739 tok/s;   1493 sec;\n","[2023-06-25 09:02:00,073 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 09:02:03,693 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.8106937408447266 s.\n","[2023-06-25 09:02:03,694 INFO] Train perplexity: 68.6885\n","[2023-06-25 09:02:03,694 INFO] Train accuracy: 47.3933\n","[2023-06-25 09:02:03,694 INFO] Sentences processed: 1.44757e+06\n","[2023-06-25 09:02:03,694 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 09:02:03,694 INFO] Validation perplexity: 20.4853\n","[2023-06-25 09:02:03,694 INFO] Validation accuracy: 63.8212\n","[2023-06-25 09:02:03,694 INFO] Model is improving ppl: 22.2544 --> 20.4853.\n","[2023-06-25 09:02:03,694 INFO] Model is improving acc: 62.4059 --> 63.8212.\n","[2023-06-25 09:02:46,269 INFO] Step 3100/ 5000; acc: 61.1; ppl:  23.5; xent: 3.2; lr: 0.00224; sents:   46772; bsz: 3735/3803/117; 32209/32794 tok/s;   1539 sec;\n","[2023-06-25 09:03:28,942 INFO] Step 3200/ 5000; acc: 61.3; ppl:  23.0; xent: 3.1; lr: 0.00221; sents:   48452; bsz: 3733/3798/121; 34993/35603 tok/s;   1582 sec;\n","[2023-06-25 09:04:47,552 INFO] Step 3300/ 5000; acc: 61.8; ppl:  22.5; xent: 3.1; lr: 0.00218; sents:   50347; bsz: 3725/3794/126; 18954/19303 tok/s;   1660 sec;\n","[2023-06-25 09:05:30,307 INFO] Step 3400/ 5000; acc: 61.7; ppl:  22.6; xent: 3.1; lr: 0.00214; sents:   47461; bsz: 3732/3800/119; 34915/35549 tok/s;   1703 sec;\n","[2023-06-25 09:06:12,744 INFO] Step 3500/ 5000; acc: 62.1; ppl:  22.1; xent: 3.1; lr: 0.00211; sents:   50512; bsz: 3724/3794/126; 35103/35759 tok/s;   1746 sec;\n","[2023-06-25 09:06:12,931 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 09:06:16,579 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.8345680236816406 s.\n","[2023-06-25 09:06:16,580 INFO] Train perplexity: 58.6609\n","[2023-06-25 09:06:16,580 INFO] Train accuracy: 49.4217\n","[2023-06-25 09:06:16,580 INFO] Sentences processed: 1.69111e+06\n","[2023-06-25 09:06:16,580 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 09:06:16,580 INFO] Validation perplexity: 19.3865\n","[2023-06-25 09:06:16,580 INFO] Validation accuracy: 64.6029\n","[2023-06-25 09:06:16,580 INFO] Model is improving ppl: 20.4853 --> 19.3865.\n","[2023-06-25 09:06:16,580 INFO] Model is improving acc: 63.8212 --> 64.6029.\n","[2023-06-25 09:06:59,203 INFO] Step 3600/ 5000; acc: 61.9; ppl:  22.2; xent: 3.1; lr: 0.00208; sents:   46948; bsz: 3734/3803/117; 32149/32743 tok/s;   1792 sec;\n","[2023-06-25 09:07:41,800 INFO] Step 3700/ 5000; acc: 62.3; ppl:  21.7; xent: 3.1; lr: 0.00205; sents:   48050; bsz: 3737/3800/120; 35091/35688 tok/s;   1835 sec;\n","[2023-06-25 09:08:24,874 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=974)\n","\n","[2023-06-25 09:08:24,875 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 2\n","[2023-06-25 09:08:56,922 INFO] Step 3800/ 5000; acc: 62.4; ppl:  21.6; xent: 3.1; lr: 0.00203; sents:   48696; bsz: 3732/3799/122; 19871/20226 tok/s;   1910 sec;\n","[2023-06-25 09:09:39,771 INFO] Step 3900/ 5000; acc: 62.2; ppl:  21.7; xent: 3.1; lr: 0.00200; sents:   47346; bsz: 3731/3799/118; 34833/35461 tok/s;   1953 sec;\n","[2023-06-25 09:10:22,248 INFO] Step 4000/ 5000; acc: 62.7; ppl:  21.1; xent: 3.1; lr: 0.00198; sents:   49470; bsz: 3729/3800/124; 35113/35783 tok/s;   1995 sec;\n","[2023-06-25 09:10:22,433 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 09:10:26,108 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.859515905380249 s.\n","[2023-06-25 09:10:26,109 INFO] Train perplexity: 51.7911\n","[2023-06-25 09:10:26,109 INFO] Train accuracy: 51.0347\n","[2023-06-25 09:10:26,109 INFO] Sentences processed: 1.93162e+06\n","[2023-06-25 09:10:26,109 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 09:10:26,109 INFO] Validation perplexity: 18.4827\n","[2023-06-25 09:10:26,109 INFO] Validation accuracy: 65.2913\n","[2023-06-25 09:10:26,110 INFO] Model is improving ppl: 19.3865 --> 18.4827.\n","[2023-06-25 09:10:26,110 INFO] Model is improving acc: 64.6029 --> 65.2913.\n","[2023-06-25 09:11:08,772 INFO] Step 4100/ 5000; acc: 62.8; ppl:  21.1; xent: 3.0; lr: 0.00195; sents:   48359; bsz: 3734/3800/121; 32106/32672 tok/s;   2042 sec;\n","[2023-06-25 09:11:51,374 INFO] Step 4200/ 5000; acc: 62.8; ppl:  20.8; xent: 3.0; lr: 0.00193; sents:   47814; bsz: 3731/3804/120; 35034/35717 tok/s;   2084 sec;\n","[2023-06-25 09:12:34,036 INFO] Step 4300/ 5000; acc: 62.9; ppl:  20.8; xent: 3.0; lr: 0.00191; sents:   48232; bsz: 3735/3798/121; 35017/35611 tok/s;   2127 sec;\n","[2023-06-25 09:13:52,464 INFO] Step 4400/ 5000; acc: 63.1; ppl:  20.5; xent: 3.0; lr: 0.00188; sents:   48095; bsz: 3733/3799/120; 19039/19378 tok/s;   2205 sec;\n","[2023-06-25 09:14:35,100 INFO] Step 4500/ 5000; acc: 63.1; ppl:  20.5; xent: 3.0; lr: 0.00186; sents:   47869; bsz: 3723/3796/120; 34926/35611 tok/s;   2248 sec;\n","[2023-06-25 09:14:35,266 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 09:14:38,882 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.7811319828033447 s.\n","[2023-06-25 09:14:38,883 INFO] Train perplexity: 46.7873\n","[2023-06-25 09:14:38,883 INFO] Train accuracy: 52.36\n","[2023-06-25 09:14:38,883 INFO] Sentences processed: 2.17199e+06\n","[2023-06-25 09:14:38,883 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 09:14:38,883 INFO] Validation perplexity: 17.9775\n","[2023-06-25 09:14:38,883 INFO] Validation accuracy: 65.8231\n","[2023-06-25 09:14:38,883 INFO] Model is improving ppl: 18.4827 --> 17.9775.\n","[2023-06-25 09:14:38,883 INFO] Model is improving acc: 65.2913 --> 65.8231.\n","[2023-06-25 09:15:21,517 INFO] Step 4600/ 5000; acc: 63.2; ppl:  20.4; xent: 3.0; lr: 0.00184; sents:   48668; bsz: 3730/3798/122; 32145/32733 tok/s;   2294 sec;\n","[2023-06-25 09:16:04,210 INFO] Step 4700/ 5000; acc: 63.5; ppl:  20.1; xent: 3.0; lr: 0.00182; sents:   48193; bsz: 3730/3800/120; 34947/35605 tok/s;   2337 sec;\n","[2023-06-25 09:16:46,773 INFO] Step 4800/ 5000; acc: 63.5; ppl:  20.1; xent: 3.0; lr: 0.00180; sents:   48000; bsz: 3732/3799/120; 35074/35702 tok/s;   2380 sec;\n","[2023-06-25 09:18:05,720 INFO] Step 4900/ 5000; acc: 63.9; ppl:  19.6; xent: 3.0; lr: 0.00179; sents:   48914; bsz: 3734/3801/122; 18917/19258 tok/s;   2459 sec;\n","[2023-06-25 09:18:48,630 INFO] Step 5000/ 5000; acc: 63.4; ppl:  20.0; xent: 3.0; lr: 0.00177; sents:   48001; bsz: 3733/3797/120; 34795/35398 tok/s;   2501 sec;\n","[2023-06-25 09:18:48,827 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 09:18:52,484 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.8525638580322266 s.\n","[2023-06-25 09:18:52,485 INFO] Train perplexity: 42.9831\n","[2023-06-25 09:18:52,485 INFO] Train accuracy: 53.4716\n","[2023-06-25 09:18:52,485 INFO] Sentences processed: 2.41377e+06\n","[2023-06-25 09:18:52,485 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 09:18:52,485 INFO] Validation perplexity: 17.4307\n","[2023-06-25 09:18:52,485 INFO] Validation accuracy: 66.1826\n","[2023-06-25 09:18:52,485 INFO] Model is improving ppl: 17.9775 --> 17.4307.\n","[2023-06-25 09:18:52,485 INFO] Model is improving acc: 65.8231 --> 66.1826.\n","[2023-06-25 09:18:52,502 INFO] Saving checkpoint models/model.fren_step_5000.pt\n"]}]},{"cell_type":"code","source":["# Train the NMT model\n","# train 3 layer 256 hidden size\n","# learning rate 3\n","# warmup steps: 4000\n","!onmt_train -config config_trans.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vpBf_81WvPWB","executionInfo":{"status":"ok","timestamp":1687691328700,"user_tz":-120,"elapsed":5008622,"user":{"displayName":"Manuel Dellabona","userId":"00334919419808458942"}},"outputId":"2f1c9924-e878-44e1-aca2-28d8497c6d65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2023-06-25 09:45:21,087 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2023-06-25 09:45:21,088 INFO] Parsed 2 corpora from -data.\n","[2023-06-25 09:45:21,089 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n","[2023-06-25 09:45:21,386 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', ',', '▁di', '.', \"'\", '▁e', '▁che']\n","[2023-06-25 09:45:21,386 INFO] The decoder start token is: <s>\n","[2023-06-25 09:45:21,386 INFO] Building model...\n","[2023-06-25 09:45:21,983 INFO] Switching model to float32 for amp/apex_amp\n","[2023-06-25 09:45:21,983 INFO] Non quantized layer compute is fp16\n","[2023-06-25 09:45:22,218 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(49440, 256, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): ModuleList(\n","      (0-2): 3 x TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_values): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_query): Linear(in_features=256, out_features=256, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=256, out_features=256, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=256, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=256, bias=False)\n","          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(48192, 256, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","    (transformer_layers): ModuleList(\n","      (0-2): 3 x TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_values): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_query): Linear(in_features=256, out_features=256, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=256, out_features=256, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=256, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=256, bias=False)\n","          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_values): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_query): Linear(in_features=256, out_features=256, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=256, out_features=256, bias=False)\n","        )\n","        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (generator): Linear(in_features=256, out_features=48192, bias=True)\n",")\n","[2023-06-25 09:45:22,220 INFO] encoder: 16592384\n","[2023-06-25 09:45:22,221 INFO] decoder: 29446208\n","[2023-06-25 09:45:22,221 INFO] * number of parameters: 46038592\n","[2023-06-25 09:45:22,221 INFO] Trainable parameters = {'torch.float32': 46038592, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2023-06-25 09:45:22,222 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2023-06-25 09:45:22,222 INFO]  * src vocab size = 49440\n","[2023-06-25 09:45:22,222 INFO]  * tgt vocab size = 48192\n","[2023-06-25 09:45:22,226 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 1\n","[2023-06-25 09:45:22,226 INFO] Starting training on GPU: [0]\n","[2023-06-25 09:45:22,226 INFO] Start training loop and validate every 500 steps...\n","[2023-06-25 09:45:22,226 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=150, tgt_seq_length=192))\n","[2023-06-25 09:46:31,524 INFO] Step 100/10000; acc: 4.7; ppl: 29470.7; xent: 10.3; lr: 0.00007; sents:   47882; bsz: 3737/3798/120; 21571/21924 tok/s;     69 sec;\n","[2023-06-25 09:47:13,817 INFO] Step 200/10000; acc: 6.0; ppl: 3946.4; xent: 8.3; lr: 0.00015; sents:   47368; bsz: 3737/3802/118; 35345/35958 tok/s;    112 sec;\n","[2023-06-25 09:47:56,127 INFO] Step 300/10000; acc: 10.2; ppl: 1185.0; xent: 7.1; lr: 0.00022; sents:   47686; bsz: 3732/3799/119; 35281/35913 tok/s;    154 sec;\n","[2023-06-25 09:48:38,371 INFO] Step 400/10000; acc: 17.8; ppl: 627.4; xent: 6.4; lr: 0.00030; sents:   49292; bsz: 3720/3792/123; 35223/35903 tok/s;    196 sec;\n","[2023-06-25 09:49:20,611 INFO] Step 500/10000; acc: 22.9; ppl: 375.5; xent: 5.9; lr: 0.00037; sents:   48366; bsz: 3734/3804/121; 35357/36021 tok/s;    238 sec;\n","[2023-06-25 09:49:24,443 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.8308985233306885 s.\n","[2023-06-25 09:49:24,443 INFO] Train perplexity: 2005.91\n","[2023-06-25 09:49:24,444 INFO] Train accuracy: 12.3269\n","[2023-06-25 09:49:24,444 INFO] Sentences processed: 240594\n","[2023-06-25 09:49:24,444 INFO] Average bsz: 3732/3799/120\n","[2023-06-25 09:49:24,444 INFO] Validation perplexity: 306.68\n","[2023-06-25 09:49:24,444 INFO] Validation accuracy: 25.0022\n","[2023-06-25 09:49:24,444 INFO] Model is improving ppl: inf --> 306.68.\n","[2023-06-25 09:49:24,444 INFO] Model is improving acc: -inf --> 25.0022.\n","[2023-06-25 09:50:40,905 INFO] Step 600/10000; acc: 26.1; ppl: 274.1; xent: 5.6; lr: 0.00045; sents:   49694; bsz: 3728/3797/124; 18574/18918 tok/s;    319 sec;\n","[2023-06-25 09:51:23,621 INFO] Step 700/10000; acc: 29.8; ppl: 206.8; xent: 5.3; lr: 0.00052; sents:   49022; bsz: 3730/3799/123; 34927/35578 tok/s;    361 sec;\n","[2023-06-25 09:52:06,281 INFO] Step 800/10000; acc: 34.0; ppl: 155.0; xent: 5.0; lr: 0.00059; sents:   50093; bsz: 3726/3797/125; 34939/35600 tok/s;    404 sec;\n","[2023-06-25 09:52:48,836 INFO] Step 900/10000; acc: 37.8; ppl: 119.2; xent: 4.8; lr: 0.00067; sents:   48346; bsz: 3730/3798/121; 35060/35703 tok/s;    447 sec;\n","[2023-06-25 09:53:31,401 INFO] Step 1000/10000; acc: 41.6; ppl:  92.2; xent: 4.5; lr: 0.00074; sents:   46359; bsz: 3737/3804/116; 35114/35749 tok/s;    489 sec;\n","[2023-06-25 09:53:31,578 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 09:53:35,223 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.8199851512908936 s.\n","[2023-06-25 09:53:35,224 INFO] Train perplexity: 561.796\n","[2023-06-25 09:53:35,224 INFO] Train accuracy: 23.0855\n","[2023-06-25 09:53:35,224 INFO] Sentences processed: 484108\n","[2023-06-25 09:53:35,224 INFO] Average bsz: 3731/3799/121\n","[2023-06-25 09:53:35,224 INFO] Validation perplexity: 70.9972\n","[2023-06-25 09:53:35,224 INFO] Validation accuracy: 46.0451\n","[2023-06-25 09:53:35,224 INFO] Model is improving ppl: 306.68 --> 70.9972.\n","[2023-06-25 09:53:35,224 INFO] Model is improving acc: 25.0022 --> 46.0451.\n","[2023-06-25 09:54:52,459 INFO] Step 1100/10000; acc: 44.8; ppl:  74.4; xent: 4.3; lr: 0.00082; sents:   47237; bsz: 3736/3801/118; 18434/18758 tok/s;    570 sec;\n","[2023-06-25 09:55:34,767 INFO] Step 1200/10000; acc: 47.5; ppl:  61.7; xent: 4.1; lr: 0.00089; sents:   48904; bsz: 3728/3797/122; 35246/35897 tok/s;    613 sec;\n","[2023-06-25 09:56:17,176 INFO] Step 1300/10000; acc: 49.6; ppl:  53.2; xent: 4.0; lr: 0.00096; sents:   49244; bsz: 3729/3797/123; 35176/35815 tok/s;    655 sec;\n","[2023-06-25 09:56:59,595 INFO] Step 1400/10000; acc: 51.3; ppl:  46.8; xent: 3.8; lr: 0.00104; sents:   48245; bsz: 3728/3795/121; 35157/35785 tok/s;    697 sec;\n","[2023-06-25 09:57:42,087 INFO] Step 1500/10000; acc: 52.6; ppl:  42.7; xent: 3.8; lr: 0.00111; sents:   48642; bsz: 3736/3801/122; 35171/35781 tok/s;    740 sec;\n","[2023-06-25 09:57:42,276 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 09:57:45,898 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.8107120990753174 s.\n","[2023-06-25 09:57:45,899 INFO] Train perplexity: 258.44\n","[2023-06-25 09:57:45,899 INFO] Train accuracy: 31.7724\n","[2023-06-25 09:57:45,899 INFO] Sentences processed: 726380\n","[2023-06-25 09:57:45,899 INFO] Average bsz: 3731/3799/121\n","[2023-06-25 09:57:45,899 INFO] Validation perplexity: 34.7636\n","[2023-06-25 09:57:45,900 INFO] Validation accuracy: 56.314\n","[2023-06-25 09:57:45,900 INFO] Model is improving ppl: 70.9972 --> 34.7636.\n","[2023-06-25 09:57:45,900 INFO] Model is improving acc: 46.0451 --> 56.314.\n","[2023-06-25 09:58:28,538 INFO] Step 1600/10000; acc: 53.3; ppl:  40.4; xent: 3.7; lr: 0.00119; sents:   46840; bsz: 3735/3802/117; 32166/32742 tok/s;    786 sec;\n","[2023-06-25 09:59:43,280 INFO] Step 1700/10000; acc: 54.5; ppl:  37.3; xent: 3.6; lr: 0.00126; sents:   48353; bsz: 3735/3801/121; 19991/20342 tok/s;    861 sec;\n","[2023-06-25 10:00:25,835 INFO] Step 1800/10000; acc: 55.3; ppl:  35.1; xent: 3.6; lr: 0.00133; sents:   46670; bsz: 3739/3806/117; 35145/35774 tok/s;    904 sec;\n","[2023-06-25 10:01:08,366 INFO] Step 1900/10000; acc: 56.2; ppl:  33.1; xent: 3.5; lr: 0.00141; sents:   49948; bsz: 3729/3797/125; 35076/35711 tok/s;    946 sec;\n","[2023-06-25 10:01:50,951 INFO] Step 2000/10000; acc: 56.1; ppl:  33.0; xent: 3.5; lr: 0.00148; sents:   47756; bsz: 3729/3796/119; 35022/35657 tok/s;    989 sec;\n","[2023-06-25 10:01:51,113 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 10:01:54,748 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.7956552505493164 s.\n","[2023-06-25 10:01:54,749 INFO] Train perplexity: 157.51\n","[2023-06-25 10:01:54,749 INFO] Train accuracy: 37.6057\n","[2023-06-25 10:01:54,750 INFO] Sentences processed: 965947\n","[2023-06-25 10:01:54,750 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 10:01:54,750 INFO] Validation perplexity: 27.4406\n","[2023-06-25 10:01:54,750 INFO] Validation accuracy: 59.6074\n","[2023-06-25 10:01:54,750 INFO] Model is improving ppl: 34.7636 --> 27.4406.\n","[2023-06-25 10:01:54,750 INFO] Model is improving acc: 56.314 --> 59.6074.\n","[2023-06-25 10:02:37,310 INFO] Step 2100/10000; acc: 57.1; ppl:  31.1; xent: 3.4; lr: 0.00156; sents:   48356; bsz: 3734/3797/121; 32217/32764 tok/s;   1035 sec;\n","[2023-06-25 10:03:55,349 INFO] Step 2200/10000; acc: 57.3; ppl:  30.5; xent: 3.4; lr: 0.00163; sents:   46175; bsz: 3744/3803/115; 19191/19495 tok/s;   1113 sec;\n","[2023-06-25 10:04:38,152 INFO] Step 2300/10000; acc: 58.0; ppl:  29.3; xent: 3.4; lr: 0.00171; sents:   49378; bsz: 3729/3794/123; 34850/35455 tok/s;   1156 sec;\n","[2023-06-25 10:05:20,613 INFO] Step 2400/10000; acc: 58.2; ppl:  28.8; xent: 3.4; lr: 0.00178; sents:   48450; bsz: 3733/3799/121; 35165/35786 tok/s;   1198 sec;\n","[2023-06-25 10:06:03,253 INFO] Step 2500/10000; acc: 58.2; ppl:  28.5; xent: 3.4; lr: 0.00185; sents:   45387; bsz: 3746/3802/113; 35137/35669 tok/s;   1241 sec;\n","[2023-06-25 10:06:03,406 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 10:06:07,115 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.8601861000061035 s.\n","[2023-06-25 10:06:07,116 INFO] Train perplexity: 112.785\n","[2023-06-25 10:06:07,116 INFO] Train accuracy: 41.6329\n","[2023-06-25 10:06:07,116 INFO] Sentences processed: 1.20369e+06\n","[2023-06-25 10:06:07,116 INFO] Average bsz: 3733/3799/120\n","[2023-06-25 10:06:07,116 INFO] Validation perplexity: 24.118\n","[2023-06-25 10:06:07,116 INFO] Validation accuracy: 61.3948\n","[2023-06-25 10:06:07,116 INFO] Model is improving ppl: 27.4406 --> 24.118.\n","[2023-06-25 10:06:07,116 INFO] Model is improving acc: 59.6074 --> 61.3948.\n","[2023-06-25 10:06:49,536 INFO] Step 2600/10000; acc: 59.0; ppl:  27.3; xent: 3.3; lr: 0.00193; sents:   50529; bsz: 3720/3794/126; 32152/32794 tok/s;   1287 sec;\n","[2023-06-25 10:07:31,991 INFO] Step 2700/10000; acc: 59.2; ppl:  26.9; xent: 3.3; lr: 0.00200; sents:   48911; bsz: 3729/3803/122; 35130/35830 tok/s;   1330 sec;\n","[2023-06-25 10:08:50,887 INFO] Step 2800/10000; acc: 59.3; ppl:  26.6; xent: 3.3; lr: 0.00208; sents:   48975; bsz: 3733/3802/122; 18925/19276 tok/s;   1409 sec;\n","[2023-06-25 10:09:33,367 INFO] Step 2900/10000; acc: 59.2; ppl:  26.6; xent: 3.3; lr: 0.00215; sents:   48245; bsz: 3731/3798/121; 35129/35760 tok/s;   1451 sec;\n","[2023-06-25 10:10:15,905 INFO] Step 3000/10000; acc: 59.6; ppl:  26.1; xent: 3.3; lr: 0.00222; sents:   47215; bsz: 3736/3803/118; 35133/35765 tok/s;   1494 sec;\n","[2023-06-25 10:10:16,099 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 10:10:19,722 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.815857172012329 s.\n","[2023-06-25 10:10:19,723 INFO] Train perplexity: 88.6988\n","[2023-06-25 10:10:19,723 INFO] Train accuracy: 44.5712\n","[2023-06-25 10:10:19,724 INFO] Sentences processed: 1.44757e+06\n","[2023-06-25 10:10:19,724 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 10:10:19,724 INFO] Validation perplexity: 22.427\n","[2023-06-25 10:10:19,724 INFO] Validation accuracy: 62.478\n","[2023-06-25 10:10:19,724 INFO] Model is improving ppl: 24.118 --> 22.427.\n","[2023-06-25 10:10:19,724 INFO] Model is improving acc: 61.3948 --> 62.478.\n","[2023-06-25 10:11:02,287 INFO] Step 3100/10000; acc: 59.7; ppl:  25.9; xent: 3.3; lr: 0.00230; sents:   46772; bsz: 3735/3803/117; 32214/32799 tok/s;   1540 sec;\n","[2023-06-25 10:11:44,902 INFO] Step 3200/10000; acc: 59.8; ppl:  25.6; xent: 3.2; lr: 0.00237; sents:   48452; bsz: 3733/3798/121; 35040/35651 tok/s;   1583 sec;\n","[2023-06-25 10:13:03,977 INFO] Step 3300/10000; acc: 60.3; ppl:  24.9; xent: 3.2; lr: 0.00245; sents:   50347; bsz: 3725/3794/126; 18842/19190 tok/s;   1662 sec;\n","[2023-06-25 10:13:46,696 INFO] Step 3400/10000; acc: 60.1; ppl:  25.2; xent: 3.2; lr: 0.00252; sents:   47461; bsz: 3732/3800/119; 34945/35579 tok/s;   1704 sec;\n","[2023-06-25 10:14:29,117 INFO] Step 3500/10000; acc: 60.5; ppl:  24.5; xent: 3.2; lr: 0.00259; sents:   50512; bsz: 3724/3794/126; 35116/35771 tok/s;   1747 sec;\n","[2023-06-25 10:14:29,310 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 10:14:32,926 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.80739688873291 s.\n","[2023-06-25 10:14:32,927 INFO] Train perplexity: 74.1141\n","[2023-06-25 10:14:32,927 INFO] Train accuracy: 46.7832\n","[2023-06-25 10:14:32,927 INFO] Sentences processed: 1.69111e+06\n","[2023-06-25 10:14:32,927 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 10:14:32,927 INFO] Validation perplexity: 21.4495\n","[2023-06-25 10:14:32,927 INFO] Validation accuracy: 63.1782\n","[2023-06-25 10:14:32,927 INFO] Model is improving ppl: 22.427 --> 21.4495.\n","[2023-06-25 10:14:32,927 INFO] Model is improving acc: 62.478 --> 63.1782.\n","[2023-06-25 10:15:15,587 INFO] Step 3600/10000; acc: 60.3; ppl:  24.7; xent: 3.2; lr: 0.00267; sents:   46948; bsz: 3734/3803/117; 32142/32736 tok/s;   1793 sec;\n","[2023-06-25 10:15:58,213 INFO] Step 3700/10000; acc: 60.6; ppl:  24.2; xent: 3.2; lr: 0.00274; sents:   48050; bsz: 3737/3800/120; 35066/35663 tok/s;   1836 sec;\n","[2023-06-25 10:16:41,439 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=974)\n","\n","[2023-06-25 10:16:41,439 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 2\n","[2023-06-25 10:17:13,861 INFO] Step 3800/10000; acc: 60.6; ppl:  24.2; xent: 3.2; lr: 0.00282; sents:   48696; bsz: 3732/3799/122; 19733/20086 tok/s;   1912 sec;\n","[2023-06-25 10:17:56,567 INFO] Step 3900/10000; acc: 60.5; ppl:  24.3; xent: 3.2; lr: 0.00289; sents:   47346; bsz: 3731/3799/118; 34949/35580 tok/s;   1954 sec;\n","[2023-06-25 10:18:38,958 INFO] Step 4000/10000; acc: 61.0; ppl:  23.7; xent: 3.2; lr: 0.00296; sents:   49470; bsz: 3729/3800/124; 35184/35856 tok/s;   1997 sec;\n","[2023-06-25 10:18:39,144 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 10:18:42,782 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.8230085372924805 s.\n","[2023-06-25 10:18:42,783 INFO] Train perplexity: 64.4431\n","[2023-06-25 10:18:42,783 INFO] Train accuracy: 48.511\n","[2023-06-25 10:18:42,783 INFO] Sentences processed: 1.93162e+06\n","[2023-06-25 10:18:42,783 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 10:18:42,783 INFO] Validation perplexity: 20.6814\n","[2023-06-25 10:18:42,783 INFO] Validation accuracy: 63.7061\n","[2023-06-25 10:18:42,783 INFO] Model is improving ppl: 21.4495 --> 20.6814.\n","[2023-06-25 10:18:42,783 INFO] Model is improving acc: 63.1782 --> 63.7061.\n","[2023-06-25 10:19:25,363 INFO] Step 4100/10000; acc: 61.0; ppl:  23.6; xent: 3.2; lr: 0.00293; sents:   48359; bsz: 3734/3800/121; 32189/32755 tok/s;   2043 sec;\n","[2023-06-25 10:20:07,887 INFO] Step 4200/10000; acc: 61.3; ppl:  23.2; xent: 3.1; lr: 0.00289; sents:   47814; bsz: 3731/3804/120; 35099/35783 tok/s;   2086 sec;\n","[2023-06-25 10:20:50,526 INFO] Step 4300/10000; acc: 61.3; ppl:  23.2; xent: 3.1; lr: 0.00286; sents:   48232; bsz: 3735/3798/121; 35035/35630 tok/s;   2128 sec;\n","[2023-06-25 10:22:09,502 INFO] Step 4400/10000; acc: 61.6; ppl:  22.7; xent: 3.1; lr: 0.00283; sents:   48095; bsz: 3733/3799/120; 18907/19244 tok/s;   2207 sec;\n","[2023-06-25 10:22:52,180 INFO] Step 4500/10000; acc: 61.7; ppl:  22.5; xent: 3.1; lr: 0.00279; sents:   47869; bsz: 3723/3796/120; 34892/35577 tok/s;   2250 sec;\n","[2023-06-25 10:22:52,343 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 10:22:55,934 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.753603458404541 s.\n","[2023-06-25 10:22:55,935 INFO] Train perplexity: 57.4821\n","[2023-06-25 10:22:55,935 INFO] Train accuracy: 49.9407\n","[2023-06-25 10:22:55,935 INFO] Sentences processed: 2.17199e+06\n","[2023-06-25 10:22:55,936 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 10:22:55,936 INFO] Validation perplexity: 19.5279\n","[2023-06-25 10:22:55,936 INFO] Validation accuracy: 64.5872\n","[2023-06-25 10:22:55,936 INFO] Model is improving ppl: 20.6814 --> 19.5279.\n","[2023-06-25 10:22:55,936 INFO] Model is improving acc: 63.7061 --> 64.5872.\n","[2023-06-25 10:23:38,533 INFO] Step 4600/10000; acc: 61.8; ppl:  22.3; xent: 3.1; lr: 0.00276; sents:   48668; bsz: 3730/3798/122; 32189/32778 tok/s;   2296 sec;\n","[2023-06-25 10:24:21,200 INFO] Step 4700/10000; acc: 62.1; ppl:  21.9; xent: 3.1; lr: 0.00273; sents:   48193; bsz: 3730/3800/120; 34968/35627 tok/s;   2339 sec;\n","[2023-06-25 10:25:03,718 INFO] Step 4800/10000; acc: 62.2; ppl:  21.8; xent: 3.1; lr: 0.00271; sents:   48000; bsz: 3732/3799/120; 35111/35740 tok/s;   2381 sec;\n","[2023-06-25 10:26:23,001 INFO] Step 4900/10000; acc: 62.6; ppl:  21.3; xent: 3.1; lr: 0.00268; sents:   48914; bsz: 3734/3801/122; 18837/19177 tok/s;   2461 sec;\n","[2023-06-25 10:27:05,774 INFO] Step 5000/10000; acc: 62.2; ppl:  21.7; xent: 3.1; lr: 0.00265; sents:   48001; bsz: 3733/3797/120; 34906/35511 tok/s;   2504 sec;\n","[2023-06-25 10:27:05,965 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 10:27:09,596 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.8211495876312256 s.\n","[2023-06-25 10:27:09,598 INFO] Train perplexity: 52.1709\n","[2023-06-25 10:27:09,598 INFO] Train accuracy: 51.1647\n","[2023-06-25 10:27:09,598 INFO] Sentences processed: 2.41377e+06\n","[2023-06-25 10:27:09,598 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 10:27:09,598 INFO] Validation perplexity: 18.6261\n","[2023-06-25 10:27:09,598 INFO] Validation accuracy: 65.2796\n","[2023-06-25 10:27:09,598 INFO] Model is improving ppl: 19.5279 --> 18.6261.\n","[2023-06-25 10:27:09,598 INFO] Model is improving acc: 64.5872 --> 65.2796.\n","[2023-06-25 10:27:09,616 INFO] Saving checkpoint models/model.fren_step_5000.pt\n","[2023-06-25 10:27:54,036 INFO] Step 5100/10000; acc: 62.6; ppl:  21.2; xent: 3.1; lr: 0.00263; sents:   48404; bsz: 3735/3799/121; 30959/31486 tok/s;   2552 sec;\n","[2023-06-25 10:28:36,551 INFO] Step 5200/10000; acc: 62.7; ppl:  21.0; xent: 3.0; lr: 0.00260; sents:   49006; bsz: 3727/3795/123; 35062/35706 tok/s;   2594 sec;\n","[2023-06-25 10:29:19,165 INFO] Step 5300/10000; acc: 62.6; ppl:  21.1; xent: 3.1; lr: 0.00258; sents:   46417; bsz: 3740/3803/116; 35105/35700 tok/s;   2637 sec;\n","[2023-06-25 10:30:01,640 INFO] Step 5400/10000; acc: 63.1; ppl:  20.6; xent: 3.0; lr: 0.00255; sents:   48377; bsz: 3734/3801/121; 35167/35792 tok/s;   2679 sec;\n","[2023-06-25 10:31:21,258 INFO] Step 5500/10000; acc: 63.2; ppl:  20.5; xent: 3.0; lr: 0.00253; sents:   50349; bsz: 3724/3797/126; 18711/19077 tok/s;   2759 sec;\n","[2023-06-25 10:31:21,412 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 10:31:25,041 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.782299041748047 s.\n","[2023-06-25 10:31:25,042 INFO] Train perplexity: 48.006\n","[2023-06-25 10:31:25,042 INFO] Train accuracy: 52.2259\n","[2023-06-25 10:31:25,042 INFO] Sentences processed: 2.65632e+06\n","[2023-06-25 10:31:25,042 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 10:31:25,042 INFO] Validation perplexity: 18.0036\n","[2023-06-25 10:31:25,042 INFO] Validation accuracy: 65.7628\n","[2023-06-25 10:31:25,042 INFO] Model is improving ppl: 18.6261 --> 18.0036.\n","[2023-06-25 10:31:25,042 INFO] Model is improving acc: 65.2796 --> 65.7628.\n","[2023-06-25 10:32:07,617 INFO] Step 5600/10000; acc: 63.1; ppl:  20.5; xent: 3.0; lr: 0.00251; sents:   47091; bsz: 3741/3802/118; 32280/32807 tok/s;   2805 sec;\n","[2023-06-25 10:32:50,290 INFO] Step 5700/10000; acc: 63.3; ppl:  20.3; xent: 3.0; lr: 0.00248; sents:   48633; bsz: 3724/3796/122; 34910/35583 tok/s;   2848 sec;\n","[2023-06-25 10:33:33,001 INFO] Step 5800/10000; acc: 63.2; ppl:  20.3; xent: 3.0; lr: 0.00246; sents:   46485; bsz: 3738/3800/116; 35007/35593 tok/s;   2891 sec;\n","[2023-06-25 10:34:15,535 INFO] Step 5900/10000; acc: 63.6; ppl:  19.9; xent: 3.0; lr: 0.00244; sents:   50990; bsz: 3725/3798/127; 35035/35719 tok/s;   2933 sec;\n","[2023-06-25 10:35:31,300 INFO] Step 6000/10000; acc: 63.6; ppl:  19.8; xent: 3.0; lr: 0.00242; sents:   47968; bsz: 3733/3802/120; 19709/20074 tok/s;   3009 sec;\n","[2023-06-25 10:35:31,494 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 10:35:35,142 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.841049909591675 s.\n","[2023-06-25 10:35:35,143 INFO] Train perplexity: 44.6591\n","[2023-06-25 10:35:35,143 INFO] Train accuracy: 53.1538\n","[2023-06-25 10:35:35,143 INFO] Sentences processed: 2.89749e+06\n","[2023-06-25 10:35:35,143 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 10:35:35,143 INFO] Validation perplexity: 17.611\n","[2023-06-25 10:35:35,143 INFO] Validation accuracy: 66.1114\n","[2023-06-25 10:35:35,143 INFO] Model is improving ppl: 18.0036 --> 17.611.\n","[2023-06-25 10:35:35,143 INFO] Model is improving acc: 65.7628 --> 66.1114.\n","[2023-06-25 10:36:17,821 INFO] Step 6100/10000; acc: 63.9; ppl:  19.6; xent: 3.0; lr: 0.00240; sents:   48505; bsz: 3735/3801/121; 32119/32679 tok/s;   3056 sec;\n","[2023-06-25 10:37:00,249 INFO] Step 6200/10000; acc: 63.8; ppl:  19.6; xent: 3.0; lr: 0.00238; sents:   48793; bsz: 3726/3796/122; 35132/35791 tok/s;   3098 sec;\n","[2023-06-25 10:37:43,018 INFO] Step 6300/10000; acc: 63.6; ppl:  19.8; xent: 3.0; lr: 0.00236; sents:   47443; bsz: 3737/3798/119; 34950/35524 tok/s;   3141 sec;\n","[2023-06-25 10:38:25,552 INFO] Step 6400/10000; acc: 63.9; ppl:  19.5; xent: 3.0; lr: 0.00234; sents:   47493; bsz: 3737/3800/119; 35141/35737 tok/s;   3183 sec;\n","[2023-06-25 10:39:08,157 INFO] Step 6500/10000; acc: 64.1; ppl:  19.2; xent: 3.0; lr: 0.00233; sents:   48930; bsz: 3731/3797/122; 35032/35652 tok/s;   3226 sec;\n","[2023-06-25 10:39:08,321 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 10:39:11,984 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.825256586074829 s.\n","[2023-06-25 10:39:11,985 INFO] Train perplexity: 41.9095\n","[2023-06-25 10:39:11,985 INFO] Train accuracy: 53.9773\n","[2023-06-25 10:39:11,985 INFO] Sentences processed: 3.13865e+06\n","[2023-06-25 10:39:11,985 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 10:39:11,985 INFO] Validation perplexity: 17.0751\n","[2023-06-25 10:39:11,985 INFO] Validation accuracy: 66.5179\n","[2023-06-25 10:39:11,985 INFO] Model is improving ppl: 17.611 --> 17.0751.\n","[2023-06-25 10:39:11,985 INFO] Model is improving acc: 66.1114 --> 66.5179.\n","[2023-06-25 10:40:30,914 INFO] Step 6600/10000; acc: 64.0; ppl:  19.3; xent: 3.0; lr: 0.00231; sents:   49413; bsz: 3731/3797/124; 18033/18353 tok/s;   3309 sec;\n","[2023-06-25 10:41:13,426 INFO] Step 6700/10000; acc: 64.2; ppl:  19.1; xent: 2.9; lr: 0.00229; sents:   48148; bsz: 3731/3801/120; 35106/35768 tok/s;   3351 sec;\n","[2023-06-25 10:41:56,141 INFO] Step 6800/10000; acc: 64.3; ppl:  19.0; xent: 2.9; lr: 0.00227; sents:   47737; bsz: 3736/3799/119; 34982/35573 tok/s;   3394 sec;\n","[2023-06-25 10:42:38,764 INFO] Step 6900/10000; acc: 64.3; ppl:  19.0; xent: 2.9; lr: 0.00226; sents:   47409; bsz: 3735/3800/119; 35053/35659 tok/s;   3437 sec;\n","[2023-06-25 10:43:21,273 INFO] Step 7000/10000; acc: 64.4; ppl:  18.9; xent: 2.9; lr: 0.00224; sents:   49400; bsz: 3726/3803/124; 35063/35785 tok/s;   3479 sec;\n","[2023-06-25 10:43:21,464 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 10:43:25,082 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.8073461055755615 s.\n","[2023-06-25 10:43:25,083 INFO] Train perplexity: 39.6167\n","[2023-06-25 10:43:25,083 INFO] Train accuracy: 54.7096\n","[2023-06-25 10:43:25,083 INFO] Sentences processed: 3.38076e+06\n","[2023-06-25 10:43:25,083 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 10:43:25,083 INFO] Validation perplexity: 16.7599\n","[2023-06-25 10:43:25,083 INFO] Validation accuracy: 66.9118\n","[2023-06-25 10:43:25,083 INFO] Model is improving ppl: 17.0751 --> 16.7599.\n","[2023-06-25 10:43:25,083 INFO] Model is improving acc: 66.5179 --> 66.9118.\n","[2023-06-25 10:44:48,321 INFO] Step 7100/10000; acc: 64.3; ppl:  18.9; xent: 2.9; lr: 0.00223; sents:   46973; bsz: 3735/3800/117; 17165/17462 tok/s;   3566 sec;\n","[2023-06-25 10:45:31,091 INFO] Step 7200/10000; acc: 64.4; ppl:  18.8; xent: 2.9; lr: 0.00221; sents:   47054; bsz: 3737/3801/118; 34946/35549 tok/s;   3609 sec;\n","[2023-06-25 10:46:13,578 INFO] Step 7300/10000; acc: 64.6; ppl:  18.6; xent: 2.9; lr: 0.00219; sents:   48635; bsz: 3730/3796/122; 35117/35743 tok/s;   3651 sec;\n","[2023-06-25 10:46:56,121 INFO] Step 7400/10000; acc: 64.7; ppl:  18.5; xent: 2.9; lr: 0.00218; sents:   50537; bsz: 3718/3789/126; 34954/35624 tok/s;   3694 sec;\n","[2023-06-25 10:47:38,615 INFO] Step 7500/10000; acc: 64.8; ppl:  18.4; xent: 2.9; lr: 0.00216; sents:   49040; bsz: 3731/3801/123; 35125/35781 tok/s;   3736 sec;\n","[2023-06-25 10:47:38,811 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 10:47:42,451 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.834585428237915 s.\n","[2023-06-25 10:47:42,452 INFO] Train perplexity: 37.6783\n","[2023-06-25 10:47:42,452 INFO] Train accuracy: 55.3656\n","[2023-06-25 10:47:42,452 INFO] Sentences processed: 3.623e+06\n","[2023-06-25 10:47:42,452 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 10:47:42,453 INFO] Validation perplexity: 16.4789\n","[2023-06-25 10:47:42,453 INFO] Validation accuracy: 67.1296\n","[2023-06-25 10:47:42,453 INFO] Model is improving ppl: 16.7599 --> 16.4789.\n","[2023-06-25 10:47:42,453 INFO] Model is improving acc: 66.9118 --> 67.1296.\n","[2023-06-25 10:48:26,552 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=977)\n","\n","[2023-06-25 10:48:26,553 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 3\n","[2023-06-25 10:48:59,223 INFO] Step 7600/10000; acc: 64.7; ppl:  18.5; xent: 2.9; lr: 0.00215; sents:   47430; bsz: 3736/3803/119; 18538/18871 tok/s;   3817 sec;\n","[2023-06-25 10:49:42,059 INFO] Step 7700/10000; acc: 64.7; ppl:  18.4; xent: 2.9; lr: 0.00214; sents:   46615; bsz: 3729/3794/117; 34826/35430 tok/s;   3860 sec;\n","[2023-06-25 10:50:24,681 INFO] Step 7800/10000; acc: 64.8; ppl:  18.3; xent: 2.9; lr: 0.00212; sents:   48853; bsz: 3729/3800/122; 35001/35666 tok/s;   3902 sec;\n","[2023-06-25 10:51:07,247 INFO] Step 7900/10000; acc: 65.0; ppl:  18.1; xent: 2.9; lr: 0.00211; sents:   49589; bsz: 3727/3796/124; 35026/35676 tok/s;   3945 sec;\n","[2023-06-25 10:51:49,869 INFO] Step 8000/10000; acc: 64.9; ppl:  18.2; xent: 2.9; lr: 0.00210; sents:   47202; bsz: 3739/3805/118; 35087/35712 tok/s;   3988 sec;\n","[2023-06-25 10:51:50,038 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 10:51:53,641 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.7712788581848145 s.\n","[2023-06-25 10:51:53,642 INFO] Train perplexity: 36.0177\n","[2023-06-25 10:51:53,642 INFO] Train accuracy: 55.9577\n","[2023-06-25 10:51:53,642 INFO] Sentences processed: 3.86269e+06\n","[2023-06-25 10:51:53,642 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 10:51:53,642 INFO] Validation perplexity: 16.2737\n","[2023-06-25 10:51:53,642 INFO] Validation accuracy: 67.2635\n","[2023-06-25 10:51:53,642 INFO] Model is improving ppl: 16.4789 --> 16.2737.\n","[2023-06-25 10:51:53,642 INFO] Model is improving acc: 67.1296 --> 67.2635.\n","[2023-06-25 10:52:36,229 INFO] Step 8100/10000; acc: 65.1; ppl:  18.0; xent: 2.9; lr: 0.00208; sents:   49691; bsz: 3727/3796/124; 32159/32755 tok/s;   4034 sec;\n","[2023-06-25 10:53:52,448 INFO] Step 8200/10000; acc: 65.1; ppl:  18.0; xent: 2.9; lr: 0.00207; sents:   48920; bsz: 3729/3804/122; 19569/19962 tok/s;   4110 sec;\n","[2023-06-25 10:54:35,116 INFO] Step 8300/10000; acc: 65.1; ppl:  18.0; xent: 2.9; lr: 0.00206; sents:   48698; bsz: 3721/3790/122; 34879/35529 tok/s;   4153 sec;\n","[2023-06-25 10:55:17,654 INFO] Step 8400/10000; acc: 65.2; ppl:  17.9; xent: 2.9; lr: 0.00205; sents:   47760; bsz: 3735/3799/119; 35121/35725 tok/s;   4195 sec;\n","[2023-06-25 10:56:00,432 INFO] Step 8500/10000; acc: 64.9; ppl:  18.2; xent: 2.9; lr: 0.00203; sents:   45616; bsz: 3738/3801/114; 34952/35539 tok/s;   4238 sec;\n","[2023-06-25 10:56:00,595 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 10:56:04,242 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.8090028762817383 s.\n","[2023-06-25 10:56:04,243 INFO] Train perplexity: 34.5789\n","[2023-06-25 10:56:04,243 INFO] Train accuracy: 56.4948\n","[2023-06-25 10:56:04,243 INFO] Sentences processed: 4.10337e+06\n","[2023-06-25 10:56:04,243 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 10:56:04,243 INFO] Validation perplexity: 16.0989\n","[2023-06-25 10:56:04,243 INFO] Validation accuracy: 67.4695\n","[2023-06-25 10:56:04,243 INFO] Model is improving ppl: 16.2737 --> 16.0989.\n","[2023-06-25 10:56:04,243 INFO] Model is improving acc: 67.2635 --> 67.4695.\n","[2023-06-25 10:56:46,861 INFO] Step 8600/10000; acc: 65.2; ppl:  17.9; xent: 2.9; lr: 0.00202; sents:   48717; bsz: 3730/3799/122; 32135/32732 tok/s;   4285 sec;\n","[2023-06-25 10:58:06,719 INFO] Step 8700/10000; acc: 65.5; ppl:  17.6; xent: 2.9; lr: 0.00201; sents:   49362; bsz: 3730/3798/123; 18683/19025 tok/s;   4364 sec;\n","[2023-06-25 10:58:49,574 INFO] Step 8800/10000; acc: 65.3; ppl:  17.8; xent: 2.9; lr: 0.00200; sents:   48120; bsz: 3736/3794/120; 34867/35410 tok/s;   4407 sec;\n","[2023-06-25 10:59:32,162 INFO] Step 8900/10000; acc: 65.5; ppl:  17.6; xent: 2.9; lr: 0.00199; sents:   47978; bsz: 3733/3803/120; 35063/35717 tok/s;   4450 sec;\n","[2023-06-25 11:00:14,820 INFO] Step 9000/10000; acc: 65.2; ppl:  17.8; xent: 2.9; lr: 0.00198; sents:   46126; bsz: 3736/3802/115; 35032/35648 tok/s;   4493 sec;\n","[2023-06-25 11:00:15,015 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 11:00:18,645 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.824737787246704 s.\n","[2023-06-25 11:00:18,647 INFO] Train perplexity: 33.319\n","[2023-06-25 11:00:18,647 INFO] Train accuracy: 56.9856\n","[2023-06-25 11:00:18,647 INFO] Sentences processed: 4.34367e+06\n","[2023-06-25 11:00:18,647 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 11:00:18,647 INFO] Validation perplexity: 15.9096\n","[2023-06-25 11:00:18,647 INFO] Validation accuracy: 67.6715\n","[2023-06-25 11:00:18,647 INFO] Model is improving ppl: 16.0989 --> 15.9096.\n","[2023-06-25 11:00:18,647 INFO] Model is improving acc: 67.4695 --> 67.6715.\n","[2023-06-25 11:01:01,361 INFO] Step 9100/10000; acc: 65.5; ppl:  17.6; xent: 2.9; lr: 0.00197; sents:   48248; bsz: 3732/3797/121; 32076/32635 tok/s;   4539 sec;\n","[2023-06-25 11:01:43,943 INFO] Step 9200/10000; acc: 65.7; ppl:  17.4; xent: 2.9; lr: 0.00195; sents:   49923; bsz: 3729/3799/125; 35025/35689 tok/s;   4582 sec;\n","[2023-06-25 11:03:04,270 INFO] Step 9300/10000; acc: 65.6; ppl:  17.4; xent: 2.9; lr: 0.00194; sents:   48413; bsz: 3730/3803/121; 18573/18940 tok/s;   4662 sec;\n","[2023-06-25 11:03:46,858 INFO] Step 9400/10000; acc: 65.7; ppl:  17.3; xent: 2.9; lr: 0.00193; sents:   48230; bsz: 3737/3801/121; 35102/35697 tok/s;   4705 sec;\n","[2023-06-25 11:04:29,421 INFO] Step 9500/10000; acc: 65.7; ppl:  17.3; xent: 2.9; lr: 0.00192; sents:   48942; bsz: 3730/3799/122; 35052/35703 tok/s;   4747 sec;\n","[2023-06-25 11:04:29,613 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 11:04:33,282 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.859358072280884 s.\n","[2023-06-25 11:04:33,283 INFO] Train perplexity: 32.2006\n","[2023-06-25 11:04:33,283 INFO] Train accuracy: 57.4403\n","[2023-06-25 11:04:33,283 INFO] Sentences processed: 4.58743e+06\n","[2023-06-25 11:04:33,283 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 11:04:33,283 INFO] Validation perplexity: 15.6781\n","[2023-06-25 11:04:33,283 INFO] Validation accuracy: 67.8627\n","[2023-06-25 11:04:33,283 INFO] Model is improving ppl: 15.9096 --> 15.6781.\n","[2023-06-25 11:04:33,283 INFO] Model is improving acc: 67.6715 --> 67.8627.\n","[2023-06-25 11:05:15,999 INFO] Step 9600/10000; acc: 65.2; ppl:  17.7; xent: 2.9; lr: 0.00191; sents:   45877; bsz: 3741/3801/115; 32129/32644 tok/s;   4794 sec;\n","[2023-06-25 11:05:58,574 INFO] Step 9700/10000; acc: 65.6; ppl:  17.4; xent: 2.9; lr: 0.00190; sents:   48528; bsz: 3731/3801/121; 35055/35708 tok/s;   4836 sec;\n","[2023-06-25 11:07:14,936 INFO] Step 9800/10000; acc: 66.0; ppl:  17.1; xent: 2.8; lr: 0.00189; sents:   49687; bsz: 3727/3796/124; 19525/19885 tok/s;   4913 sec;\n","[2023-06-25 11:07:57,791 INFO] Step 9900/10000; acc: 65.8; ppl:  17.2; xent: 2.8; lr: 0.00188; sents:   48138; bsz: 3730/3798/120; 34819/35454 tok/s;   4956 sec;\n","[2023-06-25 11:08:40,421 INFO] Step 10000/10000; acc: 66.0; ppl:  17.0; xent: 2.8; lr: 0.00187; sents:   48829; bsz: 3733/3802/122; 35029/35676 tok/s;   4998 sec;\n","[2023-06-25 11:08:40,618 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 11:08:44,265 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.8431026935577393 s.\n","[2023-06-25 11:08:44,266 INFO] Train perplexity: 31.2141\n","[2023-06-25 11:08:44,266 INFO] Train accuracy: 57.855\n","[2023-06-25 11:08:44,266 INFO] Sentences processed: 4.82849e+06\n","[2023-06-25 11:08:44,267 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 11:08:44,267 INFO] Validation perplexity: 15.5709\n","[2023-06-25 11:08:44,267 INFO] Validation accuracy: 67.8681\n","[2023-06-25 11:08:44,267 INFO] Model is improving ppl: 15.6781 --> 15.5709.\n","[2023-06-25 11:08:44,267 INFO] Model is improving acc: 67.8627 --> 67.8681.\n","[2023-06-25 11:08:44,281 INFO] Saving checkpoint models/model.fren_step_10000.pt\n"]}]},{"cell_type":"code","source":["# Train the NMT model\n","# train 4 layer 256 hidden size\n","# learning rate 3\n","# warmup steps: 2000\n","!onmt_train -config config_trans.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZWGA3GtkPisu","executionInfo":{"status":"ok","timestamp":1687696502623,"user_tz":-120,"elapsed":4948692,"user":{"displayName":"Manuel Dellabona","userId":"00334919419808458942"}},"outputId":"477b602d-86b7-4238-fd10-347d12c33436"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2023-06-25 11:12:35,292 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2023-06-25 11:12:35,293 INFO] Parsed 2 corpora from -data.\n","[2023-06-25 11:12:35,293 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n","[2023-06-25 11:12:35,584 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', ',', '▁di', '.', \"'\", '▁e', '▁che']\n","[2023-06-25 11:12:35,585 INFO] The decoder start token is: <s>\n","[2023-06-25 11:12:35,585 INFO] Building model...\n","[2023-06-25 11:12:36,256 INFO] Switching model to float32 for amp/apex_amp\n","[2023-06-25 11:12:36,256 INFO] Non quantized layer compute is fp16\n","[2023-06-25 11:12:36,495 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(49440, 256, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): ModuleList(\n","      (0-3): 4 x TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_values): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_query): Linear(in_features=256, out_features=256, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=256, out_features=256, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=256, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=256, bias=False)\n","          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(48192, 256, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","    (transformer_layers): ModuleList(\n","      (0-3): 4 x TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_values): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_query): Linear(in_features=256, out_features=256, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=256, out_features=256, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=256, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=256, bias=False)\n","          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_values): Linear(in_features=256, out_features=256, bias=False)\n","          (linear_query): Linear(in_features=256, out_features=256, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=256, out_features=256, bias=False)\n","        )\n","        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (generator): Linear(in_features=256, out_features=48192, bias=True)\n",")\n","[2023-06-25 11:12:36,497 INFO] encoder: 17904128\n","[2023-06-25 11:12:36,497 INFO] decoder: 31020608\n","[2023-06-25 11:12:36,497 INFO] * number of parameters: 48924736\n","[2023-06-25 11:12:36,498 INFO] Trainable parameters = {'torch.float32': 48924736, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2023-06-25 11:12:36,498 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2023-06-25 11:12:36,498 INFO]  * src vocab size = 49440\n","[2023-06-25 11:12:36,499 INFO]  * tgt vocab size = 48192\n","[2023-06-25 11:12:36,503 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 1\n","[2023-06-25 11:12:36,503 INFO] Starting training on GPU: [0]\n","[2023-06-25 11:12:36,503 INFO] Start training loop and validate every 500 steps...\n","[2023-06-25 11:12:36,503 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=150, tgt_seq_length=192))\n","[2023-06-25 11:13:50,392 INFO] Step 100/25000; acc: 5.3; ppl: 15446.0; xent: 9.6; lr: 0.00021; sents:   47882; bsz: 3737/3798/120; 20231/20562 tok/s;     74 sec;\n","[2023-06-25 11:14:37,406 INFO] Step 200/25000; acc: 9.7; ppl: 1234.0; xent: 7.1; lr: 0.00042; sents:   47368; bsz: 3737/3802/118; 31795/32347 tok/s;    121 sec;\n","[2023-06-25 11:15:24,514 INFO] Step 300/25000; acc: 19.6; ppl: 497.0; xent: 6.2; lr: 0.00063; sents:   47686; bsz: 3732/3799/119; 31687/32255 tok/s;    168 sec;\n","[2023-06-25 11:16:11,436 INFO] Step 400/25000; acc: 24.5; ppl: 299.6; xent: 5.7; lr: 0.00084; sents:   49292; bsz: 3720/3792/123; 31712/32324 tok/s;    215 sec;\n","[2023-06-25 11:16:58,445 INFO] Step 500/25000; acc: 28.5; ppl: 215.2; xent: 5.4; lr: 0.00105; sents:   48366; bsz: 3734/3804/121; 31770/32366 tok/s;    262 sec;\n","[2023-06-25 11:17:02,608 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.162103652954102 s.\n","[2023-06-25 11:17:02,609 INFO] Train perplexity: 906.046\n","[2023-06-25 11:17:02,609 INFO] Train accuracy: 17.5248\n","[2023-06-25 11:17:02,609 INFO] Sentences processed: 240594\n","[2023-06-25 11:17:02,609 INFO] Average bsz: 3732/3799/120\n","[2023-06-25 11:17:02,609 INFO] Validation perplexity: 173.306\n","[2023-06-25 11:17:02,609 INFO] Validation accuracy: 31.5507\n","[2023-06-25 11:17:02,609 INFO] Model is improving ppl: inf --> 173.306.\n","[2023-06-25 11:17:02,609 INFO] Model is improving acc: -inf --> 31.5507.\n","[2023-06-25 11:18:23,726 INFO] Step 600/25000; acc: 32.8; ppl: 156.2; xent: 5.1; lr: 0.00126; sents:   49694; bsz: 3728/3797/124; 17488/17812 tok/s;    347 sec;\n","[2023-06-25 11:19:11,171 INFO] Step 700/25000; acc: 37.6; ppl: 113.4; xent: 4.7; lr: 0.00147; sents:   49022; bsz: 3730/3799/123; 31446/32032 tok/s;    395 sec;\n","[2023-06-25 11:19:58,631 INFO] Step 800/25000; acc: 42.1; ppl:  83.3; xent: 4.4; lr: 0.00168; sents:   50093; bsz: 3726/3797/125; 31406/32000 tok/s;    442 sec;\n","[2023-06-25 11:20:45,989 INFO] Step 900/25000; acc: 45.7; ppl:  65.0; xent: 4.2; lr: 0.00189; sents:   48346; bsz: 3730/3798/121; 31504/32082 tok/s;    489 sec;\n","[2023-06-25 11:21:33,436 INFO] Step 1000/25000; acc: 48.3; ppl:  54.1; xent: 4.0; lr: 0.00210; sents:   46359; bsz: 3737/3804/116; 31501/32071 tok/s;    537 sec;\n","[2023-06-25 11:21:33,622 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 11:21:37,686 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.249423265457153 s.\n","[2023-06-25 11:21:37,688 INFO] Train perplexity: 281.844\n","[2023-06-25 11:21:37,688 INFO] Train accuracy: 29.4253\n","[2023-06-25 11:21:37,688 INFO] Sentences processed: 484108\n","[2023-06-25 11:21:37,688 INFO] Average bsz: 3731/3799/121\n","[2023-06-25 11:21:37,688 INFO] Validation perplexity: 42.7238\n","[2023-06-25 11:21:37,688 INFO] Validation accuracy: 52.5357\n","[2023-06-25 11:21:37,688 INFO] Model is improving ppl: 173.306 --> 42.7238.\n","[2023-06-25 11:21:37,688 INFO] Model is improving acc: 31.5507 --> 52.5357.\n","[2023-06-25 11:23:00,169 INFO] Step 1100/25000; acc: 50.3; ppl:  47.5; xent: 3.9; lr: 0.00231; sents:   47237; bsz: 3736/3801/118; 17228/17531 tok/s;    624 sec;\n","[2023-06-25 11:23:47,779 INFO] Step 1200/25000; acc: 52.3; ppl:  41.9; xent: 3.7; lr: 0.00252; sents:   48904; bsz: 3728/3797/122; 31321/31899 tok/s;    671 sec;\n","[2023-06-25 11:24:35,114 INFO] Step 1300/25000; acc: 53.2; ppl:  39.1; xent: 3.7; lr: 0.00273; sents:   49244; bsz: 3729/3797/123; 31516/32088 tok/s;    719 sec;\n","[2023-06-25 11:25:22,431 INFO] Step 1400/25000; acc: 54.2; ppl:  36.6; xent: 3.6; lr: 0.00294; sents:   48245; bsz: 3728/3795/121; 31517/32081 tok/s;    766 sec;\n","[2023-06-25 11:26:09,748 INFO] Step 1500/25000; acc: 55.2; ppl:  34.4; xent: 3.5; lr: 0.00315; sents:   48642; bsz: 3736/3801/122; 31585/32132 tok/s;    813 sec;\n","[2023-06-25 11:26:09,940 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 11:26:13,959 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.209884881973267 s.\n","[2023-06-25 11:26:13,960 INFO] Train perplexity: 146.574\n","[2023-06-25 11:26:13,960 INFO] Train accuracy: 37.2934\n","[2023-06-25 11:26:13,960 INFO] Sentences processed: 726380\n","[2023-06-25 11:26:13,960 INFO] Average bsz: 3731/3799/121\n","[2023-06-25 11:26:13,960 INFO] Validation perplexity: 28.9382\n","[2023-06-25 11:26:13,960 INFO] Validation accuracy: 58.4483\n","[2023-06-25 11:26:13,960 INFO] Model is improving ppl: 42.7238 --> 28.9382.\n","[2023-06-25 11:26:13,960 INFO] Model is improving acc: 52.5357 --> 58.4483.\n","[2023-06-25 11:27:01,547 INFO] Step 1600/25000; acc: 55.5; ppl:  33.6; xent: 3.5; lr: 0.00336; sents:   46840; bsz: 3735/3802/117; 28846/29362 tok/s;    865 sec;\n","[2023-06-25 11:28:21,848 INFO] Step 1700/25000; acc: 56.1; ppl:  32.2; xent: 3.5; lr: 0.00357; sents:   48353; bsz: 3735/3801/121; 18608/18934 tok/s;    945 sec;\n","[2023-06-25 11:29:09,210 INFO] Step 1800/25000; acc: 56.8; ppl:  30.9; xent: 3.4; lr: 0.00378; sents:   46670; bsz: 3739/3806/117; 31578/32143 tok/s;    993 sec;\n","[2023-06-25 11:29:56,617 INFO] Step 1900/25000; acc: 57.4; ppl:  29.8; xent: 3.4; lr: 0.00399; sents:   49948; bsz: 3729/3797/125; 31468/32038 tok/s;   1040 sec;\n","[2023-06-25 11:30:44,100 INFO] Step 2000/25000; acc: 57.3; ppl:  29.8; xent: 3.4; lr: 0.00419; sents:   47756; bsz: 3729/3796/119; 31409/31979 tok/s;   1088 sec;\n","[2023-06-25 11:30:44,291 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 11:30:48,313 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.211910963058472 s.\n","[2023-06-25 11:30:48,315 INFO] Train perplexity: 99.5685\n","[2023-06-25 11:30:48,315 INFO] Train accuracy: 42.1258\n","[2023-06-25 11:30:48,315 INFO] Sentences processed: 965947\n","[2023-06-25 11:30:48,315 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 11:30:48,315 INFO] Validation perplexity: 25.2311\n","[2023-06-25 11:30:48,315 INFO] Validation accuracy: 60.386\n","[2023-06-25 11:30:48,315 INFO] Model is improving ppl: 28.9382 --> 25.2311.\n","[2023-06-25 11:30:48,315 INFO] Model is improving acc: 58.4483 --> 60.386.\n","[2023-06-25 11:31:35,746 INFO] Step 2100/25000; acc: 58.0; ppl:  28.6; xent: 3.4; lr: 0.00409; sents:   48356; bsz: 3734/3797/121; 28919/29410 tok/s;   1139 sec;\n","[2023-06-25 11:32:59,903 INFO] Step 2200/25000; acc: 58.4; ppl:  27.8; xent: 3.3; lr: 0.00400; sents:   46175; bsz: 3744/3803/115; 17796/18078 tok/s;   1223 sec;\n","[2023-06-25 11:33:47,526 INFO] Step 2300/25000; acc: 59.1; ppl:  26.6; xent: 3.3; lr: 0.00391; sents:   49378; bsz: 3729/3794/123; 31323/31866 tok/s;   1271 sec;\n","[2023-06-25 11:34:34,901 INFO] Step 2400/25000; acc: 59.4; ppl:  26.1; xent: 3.3; lr: 0.00383; sents:   48450; bsz: 3733/3799/121; 31517/32073 tok/s;   1318 sec;\n","[2023-06-25 11:35:22,495 INFO] Step 2500/25000; acc: 59.6; ppl:  25.6; xent: 3.2; lr: 0.00375; sents:   45387; bsz: 3746/3802/113; 31480/31957 tok/s;   1366 sec;\n","[2023-06-25 11:35:22,687 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 11:35:26,756 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.259751081466675 s.\n","[2023-06-25 11:35:26,757 INFO] Train perplexity: 76.6422\n","[2023-06-25 11:35:26,757 INFO] Train accuracy: 45.4779\n","[2023-06-25 11:35:26,757 INFO] Sentences processed: 1.20369e+06\n","[2023-06-25 11:35:26,757 INFO] Average bsz: 3733/3799/120\n","[2023-06-25 11:35:26,757 INFO] Validation perplexity: 21.9041\n","[2023-06-25 11:35:26,757 INFO] Validation accuracy: 62.5453\n","[2023-06-25 11:35:26,757 INFO] Model is improving ppl: 25.2311 --> 21.9041.\n","[2023-06-25 11:35:26,757 INFO] Model is improving acc: 60.386 --> 62.5453.\n","[2023-06-25 11:36:14,106 INFO] Step 2600/25000; acc: 60.4; ppl:  24.5; xent: 3.2; lr: 0.00368; sents:   50529; bsz: 3720/3794/126; 28833/29409 tok/s;   1418 sec;\n","[2023-06-25 11:37:01,455 INFO] Step 2700/25000; acc: 60.7; ppl:  24.0; xent: 3.2; lr: 0.00361; sents:   48911; bsz: 3729/3803/122; 31499/32127 tok/s;   1465 sec;\n","[2023-06-25 11:38:22,474 INFO] Step 2800/25000; acc: 60.8; ppl:  23.8; xent: 3.2; lr: 0.00354; sents:   48975; bsz: 3733/3802/122; 18429/18771 tok/s;   1546 sec;\n","[2023-06-25 11:39:09,844 INFO] Step 2900/25000; acc: 60.8; ppl:  23.7; xent: 3.2; lr: 0.00348; sents:   48245; bsz: 3731/3798/121; 31503/32068 tok/s;   1593 sec;\n","[2023-06-25 11:39:57,197 INFO] Step 3000/25000; acc: 61.2; ppl:  23.1; xent: 3.1; lr: 0.00342; sents:   47215; bsz: 3736/3803/118; 31561/32128 tok/s;   1641 sec;\n","[2023-06-25 11:39:57,385 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 11:40:01,468 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.269526481628418 s.\n","[2023-06-25 11:40:01,470 INFO] Train perplexity: 63.083\n","[2023-06-25 11:40:01,470 INFO] Train accuracy: 48.0264\n","[2023-06-25 11:40:01,470 INFO] Sentences processed: 1.44757e+06\n","[2023-06-25 11:40:01,470 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 11:40:01,470 INFO] Validation perplexity: 20.1197\n","[2023-06-25 11:40:01,470 INFO] Validation accuracy: 64.0319\n","[2023-06-25 11:40:01,470 INFO] Model is improving ppl: 21.9041 --> 20.1197.\n","[2023-06-25 11:40:01,470 INFO] Model is improving acc: 62.5453 --> 64.0319.\n","[2023-06-25 11:40:48,895 INFO] Step 3100/25000; acc: 61.2; ppl:  23.1; xent: 3.1; lr: 0.00337; sents:   46772; bsz: 3735/3803/117; 28901/29426 tok/s;   1692 sec;\n","[2023-06-25 11:41:36,344 INFO] Step 3200/25000; acc: 61.5; ppl:  22.6; xent: 3.1; lr: 0.00331; sents:   48452; bsz: 3733/3798/121; 31470/32019 tok/s;   1740 sec;\n","[2023-06-25 11:43:00,463 INFO] Step 3300/25000; acc: 62.0; ppl:  22.1; xent: 3.1; lr: 0.00326; sents:   50347; bsz: 3725/3794/126; 17712/18039 tok/s;   1824 sec;\n","[2023-06-25 11:43:48,039 INFO] Step 3400/25000; acc: 61.9; ppl:  22.0; xent: 3.1; lr: 0.00322; sents:   47461; bsz: 3732/3800/119; 31377/31946 tok/s;   1872 sec;\n","[2023-06-25 11:44:35,279 INFO] Step 3500/25000; acc: 62.2; ppl:  21.7; xent: 3.1; lr: 0.00317; sents:   50512; bsz: 3724/3794/126; 31534/32123 tok/s;   1919 sec;\n","[2023-06-25 11:44:35,448 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 11:44:39,485 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.204567909240723 s.\n","[2023-06-25 11:44:39,486 INFO] Train perplexity: 54.3732\n","[2023-06-25 11:44:39,486 INFO] Train accuracy: 49.9894\n","[2023-06-25 11:44:39,486 INFO] Sentences processed: 1.69111e+06\n","[2023-06-25 11:44:39,486 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 11:44:39,486 INFO] Validation perplexity: 19.033\n","[2023-06-25 11:44:39,486 INFO] Validation accuracy: 64.8128\n","[2023-06-25 11:44:39,486 INFO] Model is improving ppl: 20.1197 --> 19.033.\n","[2023-06-25 11:44:39,486 INFO] Model is improving acc: 64.0319 --> 64.8128.\n","[2023-06-25 11:45:26,969 INFO] Step 3600/25000; acc: 62.2; ppl:  21.7; xent: 3.1; lr: 0.00312; sents:   46948; bsz: 3734/3803/117; 28896/29429 tok/s;   1970 sec;\n","[2023-06-25 11:46:14,498 INFO] Step 3700/25000; acc: 62.5; ppl:  21.2; xent: 3.1; lr: 0.00308; sents:   48050; bsz: 3737/3800/120; 31450/31985 tok/s;   2018 sec;\n","[2023-06-25 11:47:02,374 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=974)\n","\n","[2023-06-25 11:47:02,374 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 2\n","[2023-06-25 11:47:35,732 INFO] Step 3800/25000; acc: 62.6; ppl:  21.2; xent: 3.1; lr: 0.00304; sents:   48696; bsz: 3732/3799/122; 18376/18705 tok/s;   2099 sec;\n","[2023-06-25 11:48:23,410 INFO] Step 3900/25000; acc: 62.5; ppl:  21.2; xent: 3.1; lr: 0.00300; sents:   47346; bsz: 3731/3799/118; 31304/31869 tok/s;   2147 sec;\n","[2023-06-25 11:49:10,624 INFO] Step 4000/25000; acc: 63.0; ppl:  20.6; xent: 3.0; lr: 0.00296; sents:   49470; bsz: 3729/3800/124; 31589/32193 tok/s;   2194 sec;\n","[2023-06-25 11:49:10,788 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 11:49:14,857 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.231084823608398 s.\n","[2023-06-25 11:49:14,858 INFO] Train perplexity: 48.3294\n","[2023-06-25 11:49:14,858 INFO] Train accuracy: 51.5586\n","[2023-06-25 11:49:14,858 INFO] Sentences processed: 1.93162e+06\n","[2023-06-25 11:49:14,858 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 11:49:14,858 INFO] Validation perplexity: 18.2321\n","[2023-06-25 11:49:14,858 INFO] Validation accuracy: 65.4487\n","[2023-06-25 11:49:14,858 INFO] Model is improving ppl: 19.033 --> 18.2321.\n","[2023-06-25 11:49:14,858 INFO] Model is improving acc: 64.8128 --> 65.4487.\n","[2023-06-25 11:50:02,328 INFO] Step 4100/25000; acc: 63.0; ppl:  20.6; xent: 3.0; lr: 0.00293; sents:   48359; bsz: 3734/3800/121; 28890/29399 tok/s;   2246 sec;\n","[2023-06-25 11:50:49,765 INFO] Step 4200/25000; acc: 63.1; ppl:  20.4; xent: 3.0; lr: 0.00289; sents:   47814; bsz: 3731/3804/120; 31463/32077 tok/s;   2293 sec;\n","[2023-06-25 11:51:37,278 INFO] Step 4300/25000; acc: 63.2; ppl:  20.4; xent: 3.0; lr: 0.00286; sents:   48232; bsz: 3735/3798/121; 31441/31975 tok/s;   2341 sec;\n","[2023-06-25 11:53:02,007 INFO] Step 4400/25000; acc: 63.3; ppl:  20.1; xent: 3.0; lr: 0.00283; sents:   48095; bsz: 3733/3799/120; 17624/17937 tok/s;   2426 sec;\n","[2023-06-25 11:53:49,499 INFO] Step 4500/25000; acc: 63.4; ppl:  20.0; xent: 3.0; lr: 0.00279; sents:   47869; bsz: 3723/3796/120; 31354/31970 tok/s;   2473 sec;\n","[2023-06-25 11:53:49,694 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 11:53:53,708 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.20758581161499 s.\n","[2023-06-25 11:53:53,710 INFO] Train perplexity: 43.887\n","[2023-06-25 11:53:53,710 INFO] Train accuracy: 52.8532\n","[2023-06-25 11:53:53,710 INFO] Sentences processed: 2.17199e+06\n","[2023-06-25 11:53:53,710 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 11:53:53,710 INFO] Validation perplexity: 17.6542\n","[2023-06-25 11:53:53,710 INFO] Validation accuracy: 66.0158\n","[2023-06-25 11:53:53,710 INFO] Model is improving ppl: 18.2321 --> 17.6542.\n","[2023-06-25 11:53:53,710 INFO] Model is improving acc: 65.4487 --> 66.0158.\n","[2023-06-25 11:54:41,266 INFO] Step 4600/25000; acc: 63.4; ppl:  19.9; xent: 3.0; lr: 0.00276; sents:   48668; bsz: 3730/3798/122; 28823/29350 tok/s;   2525 sec;\n","[2023-06-25 11:55:28,814 INFO] Step 4700/25000; acc: 63.7; ppl:  19.6; xent: 3.0; lr: 0.00273; sents:   48193; bsz: 3730/3800/120; 31378/31970 tok/s;   2572 sec;\n","[2023-06-25 11:56:16,226 INFO] Step 4800/25000; acc: 63.8; ppl:  19.6; xent: 3.0; lr: 0.00271; sents:   48000; bsz: 3732/3799/120; 31488/32051 tok/s;   2620 sec;\n","[2023-06-25 11:57:37,040 INFO] Step 4900/25000; acc: 64.2; ppl:  19.2; xent: 3.0; lr: 0.00268; sents:   48914; bsz: 3734/3801/122; 18480/18813 tok/s;   2701 sec;\n","[2023-06-25 11:58:24,804 INFO] Step 5000/25000; acc: 63.7; ppl:  19.6; xent: 3.0; lr: 0.00265; sents:   48001; bsz: 3733/3797/120; 31259/31801 tok/s;   2748 sec;\n","[2023-06-25 11:58:24,996 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 11:58:28,990 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.185354232788086 s.\n","[2023-06-25 11:58:28,992 INFO] Train perplexity: 40.4824\n","[2023-06-25 11:58:28,992 INFO] Train accuracy: 53.9437\n","[2023-06-25 11:58:28,992 INFO] Sentences processed: 2.41377e+06\n","[2023-06-25 11:58:28,992 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 11:58:28,992 INFO] Validation perplexity: 17.1091\n","[2023-06-25 11:58:28,992 INFO] Validation accuracy: 66.3933\n","[2023-06-25 11:58:28,992 INFO] Model is improving ppl: 17.6542 --> 17.1091.\n","[2023-06-25 11:58:28,992 INFO] Model is improving acc: 66.0158 --> 66.3933.\n","[2023-06-25 11:58:29,008 INFO] Saving checkpoint models/model.fren_step_5000.pt\n","[2023-06-25 11:59:18,233 INFO] Step 5100/25000; acc: 64.1; ppl:  19.1; xent: 3.0; lr: 0.00263; sents:   48404; bsz: 3735/3799/121; 27964/28440 tok/s;   2802 sec;\n","[2023-06-25 12:00:05,638 INFO] Step 5200/25000; acc: 64.2; ppl:  19.0; xent: 2.9; lr: 0.00260; sents:   49006; bsz: 3727/3795/123; 31446/32023 tok/s;   2849 sec;\n","[2023-06-25 12:00:53,206 INFO] Step 5300/25000; acc: 64.1; ppl:  19.1; xent: 3.0; lr: 0.00258; sents:   46417; bsz: 3740/3803/116; 31449/31982 tok/s;   2897 sec;\n","[2023-06-25 12:01:40,599 INFO] Step 5400/25000; acc: 64.4; ppl:  18.8; xent: 2.9; lr: 0.00255; sents:   48377; bsz: 3734/3801/121; 31518/32078 tok/s;   2944 sec;\n","[2023-06-25 12:03:05,593 INFO] Step 5500/25000; acc: 64.6; ppl:  18.6; xent: 2.9; lr: 0.00253; sents:   50349; bsz: 3724/3797/126; 17528/17870 tok/s;   3029 sec;\n","[2023-06-25 12:03:05,799 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 12:03:09,856 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.261244297027588 s.\n","[2023-06-25 12:03:09,857 INFO] Train perplexity: 37.7796\n","[2023-06-25 12:03:09,857 INFO] Train accuracy: 54.8816\n","[2023-06-25 12:03:09,857 INFO] Sentences processed: 2.65632e+06\n","[2023-06-25 12:03:09,857 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 12:03:09,857 INFO] Validation perplexity: 16.6907\n","[2023-06-25 12:03:09,857 INFO] Validation accuracy: 66.8061\n","[2023-06-25 12:03:09,857 INFO] Model is improving ppl: 17.1091 --> 16.6907.\n","[2023-06-25 12:03:09,857 INFO] Model is improving acc: 66.3933 --> 66.8061.\n","[2023-06-25 12:03:57,280 INFO] Step 5600/25000; acc: 64.5; ppl:  18.6; xent: 2.9; lr: 0.00251; sents:   47091; bsz: 3741/3802/118; 28953/29426 tok/s;   3081 sec;\n","[2023-06-25 12:04:44,759 INFO] Step 5700/25000; acc: 64.6; ppl:  18.5; xent: 2.9; lr: 0.00248; sents:   48633; bsz: 3724/3796/122; 31376/31981 tok/s;   3128 sec;\n","[2023-06-25 12:05:32,379 INFO] Step 5800/25000; acc: 64.6; ppl:  18.5; xent: 2.9; lr: 0.00246; sents:   46485; bsz: 3738/3800/116; 31398/31924 tok/s;   3176 sec;\n","[2023-06-25 12:06:19,794 INFO] Step 5900/25000; acc: 64.9; ppl:  18.2; xent: 2.9; lr: 0.00244; sents:   50990; bsz: 3725/3798/127; 31428/32043 tok/s;   3223 sec;\n","[2023-06-25 12:07:41,191 INFO] Step 6000/25000; acc: 64.9; ppl:  18.1; xent: 2.9; lr: 0.00242; sents:   47968; bsz: 3733/3802/120; 18345/18685 tok/s;   3305 sec;\n","[2023-06-25 12:07:41,363 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 12:07:45,427 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.234788417816162 s.\n","[2023-06-25 12:07:45,429 INFO] Train perplexity: 35.5812\n","[2023-06-25 12:07:45,429 INFO] Train accuracy: 55.6999\n","[2023-06-25 12:07:45,429 INFO] Sentences processed: 2.89749e+06\n","[2023-06-25 12:07:45,429 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 12:07:45,429 INFO] Validation perplexity: 16.3483\n","[2023-06-25 12:07:45,429 INFO] Validation accuracy: 67.0121\n","[2023-06-25 12:07:45,429 INFO] Model is improving ppl: 16.6907 --> 16.3483.\n","[2023-06-25 12:07:45,429 INFO] Model is improving acc: 66.8061 --> 67.0121.\n","[2023-06-25 12:08:33,070 INFO] Step 6100/25000; acc: 65.1; ppl:  17.9; xent: 2.9; lr: 0.00240; sents:   48505; bsz: 3735/3801/121; 28802/29305 tok/s;   3357 sec;\n","[2023-06-25 12:09:20,378 INFO] Step 6200/25000; acc: 65.0; ppl:  18.0; xent: 2.9; lr: 0.00238; sents:   48793; bsz: 3726/3796/122; 31508/32099 tok/s;   3404 sec;\n","[2023-06-25 12:10:08,009 INFO] Step 6300/25000; acc: 64.9; ppl:  18.1; xent: 2.9; lr: 0.00236; sents:   47443; bsz: 3737/3798/119; 31383/31898 tok/s;   3452 sec;\n","[2023-06-25 12:10:55,524 INFO] Step 6400/25000; acc: 65.1; ppl:  17.9; xent: 2.9; lr: 0.00234; sents:   47493; bsz: 3737/3800/119; 31456/31989 tok/s;   3499 sec;\n","[2023-06-25 12:11:43,020 INFO] Step 6500/25000; acc: 65.3; ppl:  17.7; xent: 2.9; lr: 0.00233; sents:   48930; bsz: 3731/3797/122; 31425/31981 tok/s;   3547 sec;\n","[2023-06-25 12:11:43,181 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 12:11:47,268 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.246051549911499 s.\n","[2023-06-25 12:11:47,269 INFO] Train perplexity: 33.7559\n","[2023-06-25 12:11:47,269 INFO] Train accuracy: 56.4231\n","[2023-06-25 12:11:47,269 INFO] Sentences processed: 3.13865e+06\n","[2023-06-25 12:11:47,269 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 12:11:47,269 INFO] Validation perplexity: 16.0297\n","[2023-06-25 12:11:47,269 INFO] Validation accuracy: 67.4334\n","[2023-06-25 12:11:47,270 INFO] Model is improving ppl: 16.3483 --> 16.0297.\n","[2023-06-25 12:11:47,270 INFO] Model is improving acc: 67.0121 --> 67.4334.\n","[2023-06-25 12:13:11,930 INFO] Step 6600/25000; acc: 65.2; ppl:  17.8; xent: 2.9; lr: 0.00231; sents:   49413; bsz: 3731/3797/124; 16785/17083 tok/s;   3635 sec;\n","[2023-06-25 12:13:59,259 INFO] Step 6700/25000; acc: 65.4; ppl:  17.6; xent: 2.9; lr: 0.00229; sents:   48148; bsz: 3731/3801/120; 31534/32128 tok/s;   3683 sec;\n","[2023-06-25 12:14:46,921 INFO] Step 6800/25000; acc: 65.4; ppl:  17.6; xent: 2.9; lr: 0.00227; sents:   47737; bsz: 3736/3799/119; 31350/31879 tok/s;   3730 sec;\n","[2023-06-25 12:15:34,416 INFO] Step 6900/25000; acc: 65.4; ppl:  17.6; xent: 2.9; lr: 0.00226; sents:   47409; bsz: 3735/3800/119; 31457/32001 tok/s;   3778 sec;\n","[2023-06-25 12:16:21,911 INFO] Step 7000/25000; acc: 65.6; ppl:  17.5; xent: 2.9; lr: 0.00224; sents:   49400; bsz: 3726/3803/124; 31383/32029 tok/s;   3825 sec;\n","[2023-06-25 12:16:22,074 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 12:16:26,091 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.179252624511719 s.\n","[2023-06-25 12:16:26,092 INFO] Train perplexity: 32.2228\n","[2023-06-25 12:16:26,092 INFO] Train accuracy: 57.0644\n","[2023-06-25 12:16:26,092 INFO] Sentences processed: 3.38076e+06\n","[2023-06-25 12:16:26,092 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 12:16:26,092 INFO] Validation perplexity: 15.8396\n","[2023-06-25 12:16:26,093 INFO] Validation accuracy: 67.6136\n","[2023-06-25 12:16:26,093 INFO] Model is improving ppl: 16.0297 --> 15.8396.\n","[2023-06-25 12:16:26,093 INFO] Model is improving acc: 67.4334 --> 67.6136.\n","[2023-06-25 12:17:51,363 INFO] Step 7100/25000; acc: 65.4; ppl:  17.6; xent: 2.9; lr: 0.00223; sents:   46973; bsz: 3735/3800/117; 16703/16993 tok/s;   3915 sec;\n","[2023-06-25 12:18:39,090 INFO] Step 7200/25000; acc: 65.6; ppl:  17.5; xent: 2.9; lr: 0.00221; sents:   47054; bsz: 3737/3801/118; 31316/31856 tok/s;   3963 sec;\n","[2023-06-25 12:19:26,542 INFO] Step 7300/25000; acc: 65.7; ppl:  17.3; xent: 2.8; lr: 0.00219; sents:   48635; bsz: 3730/3796/122; 31443/32004 tok/s;   4010 sec;\n","[2023-06-25 12:20:13,952 INFO] Step 7400/25000; acc: 65.8; ppl:  17.2; xent: 2.8; lr: 0.00218; sents:   50537; bsz: 3718/3789/126; 31366/31967 tok/s;   4057 sec;\n","[2023-06-25 12:21:01,309 INFO] Step 7500/25000; acc: 65.8; ppl:  17.1; xent: 2.8; lr: 0.00216; sents:   49040; bsz: 3731/3801/123; 31518/32107 tok/s;   4105 sec;\n","[2023-06-25 12:21:01,476 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 12:21:05,500 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.190061569213867 s.\n","[2023-06-25 12:21:05,502 INFO] Train perplexity: 30.9187\n","[2023-06-25 12:21:05,502 INFO] Train accuracy: 57.6369\n","[2023-06-25 12:21:05,502 INFO] Sentences processed: 3.623e+06\n","[2023-06-25 12:21:05,502 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 12:21:05,502 INFO] Validation perplexity: 15.5758\n","[2023-06-25 12:21:05,502 INFO] Validation accuracy: 67.8446\n","[2023-06-25 12:21:05,502 INFO] Model is improving ppl: 15.8396 --> 15.5758.\n","[2023-06-25 12:21:05,502 INFO] Model is improving acc: 67.6136 --> 67.8446.\n","[2023-06-25 12:21:54,329 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=977)\n","\n","[2023-06-25 12:21:54,329 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 3\n","[2023-06-25 12:22:26,923 INFO] Step 7600/25000; acc: 65.7; ppl:  17.3; xent: 2.8; lr: 0.00215; sents:   47430; bsz: 3736/3803/119; 17454/17768 tok/s;   4190 sec;\n","[2023-06-25 12:23:14,824 INFO] Step 7700/25000; acc: 65.7; ppl:  17.2; xent: 2.8; lr: 0.00214; sents:   46615; bsz: 3729/3794/117; 31143/31683 tok/s;   4238 sec;\n","[2023-06-25 12:24:02,489 INFO] Step 7800/25000; acc: 65.9; ppl:  17.1; xent: 2.8; lr: 0.00212; sents:   48853; bsz: 3729/3800/122; 31298/31893 tok/s;   4286 sec;\n","[2023-06-25 12:24:50,255 INFO] Step 7900/25000; acc: 66.1; ppl:  17.0; xent: 2.8; lr: 0.00211; sents:   49589; bsz: 3727/3796/124; 31213/31792 tok/s;   4334 sec;\n","[2023-06-25 12:25:37,880 INFO] Step 8000/25000; acc: 65.8; ppl:  17.1; xent: 2.8; lr: 0.00210; sents:   47202; bsz: 3739/3805/118; 31401/31960 tok/s;   4381 sec;\n","[2023-06-25 12:25:38,036 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 12:25:42,050 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.1684370040893555 s.\n","[2023-06-25 12:25:42,051 INFO] Train perplexity: 29.7975\n","[2023-06-25 12:25:42,051 INFO] Train accuracy: 58.1495\n","[2023-06-25 12:25:42,051 INFO] Sentences processed: 3.86269e+06\n","[2023-06-25 12:25:42,051 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 12:25:42,051 INFO] Validation perplexity: 15.4962\n","[2023-06-25 12:25:42,051 INFO] Validation accuracy: 68.013\n","[2023-06-25 12:25:42,051 INFO] Model is improving ppl: 15.5758 --> 15.4962.\n","[2023-06-25 12:25:42,052 INFO] Model is improving acc: 67.8446 --> 68.013.\n","[2023-06-25 12:26:29,573 INFO] Step 8100/25000; acc: 66.1; ppl:  16.9; xent: 2.8; lr: 0.00208; sents:   49691; bsz: 3727/3796/124; 28841/29376 tok/s;   4433 sec;\n","[2023-06-25 12:27:54,761 INFO] Step 8200/25000; acc: 66.0; ppl:  16.9; xent: 2.8; lr: 0.00207; sents:   48920; bsz: 3729/3804/122; 17509/17860 tok/s;   4518 sec;\n","[2023-06-25 12:28:42,264 INFO] Step 8300/25000; acc: 66.1; ppl:  16.9; xent: 2.8; lr: 0.00206; sents:   48698; bsz: 3721/3790/122; 31329/31913 tok/s;   4566 sec;\n","[2023-06-25 12:29:29,790 INFO] Step 8400/25000; acc: 66.2; ppl:  16.8; xent: 2.8; lr: 0.00205; sents:   47760; bsz: 3735/3799/119; 31435/31976 tok/s;   4613 sec;\n","[2023-06-25 12:30:17,588 INFO] Step 8500/25000; acc: 65.8; ppl:  17.0; xent: 2.8; lr: 0.00203; sents:   45616; bsz: 3738/3801/114; 31280/31806 tok/s;   4661 sec;\n","[2023-06-25 12:30:17,800 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 12:30:21,854 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.2647576332092285 s.\n","[2023-06-25 12:30:21,855 INFO] Train perplexity: 28.8192\n","[2023-06-25 12:30:21,856 INFO] Train accuracy: 58.6138\n","[2023-06-25 12:30:21,856 INFO] Sentences processed: 4.10337e+06\n","[2023-06-25 12:30:21,856 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 12:30:21,856 INFO] Validation perplexity: 15.3324\n","[2023-06-25 12:30:21,856 INFO] Validation accuracy: 68.0647\n","[2023-06-25 12:30:21,856 INFO] Model is improving ppl: 15.4962 --> 15.3324.\n","[2023-06-25 12:30:21,856 INFO] Model is improving acc: 68.013 --> 68.0647.\n","[2023-06-25 12:31:09,687 INFO] Step 8600/25000; acc: 66.1; ppl:  16.8; xent: 2.8; lr: 0.00202; sents:   48717; bsz: 3730/3799/122; 28639/29171 tok/s;   4713 sec;\n","[2023-06-25 12:32:36,371 INFO] Step 8700/25000; acc: 66.4; ppl:  16.6; xent: 2.8; lr: 0.00201; sents:   49362; bsz: 3730/3798/123; 17212/17527 tok/s;   4800 sec;\n","[2023-06-25 12:33:24,382 INFO] Step 8800/25000; acc: 66.2; ppl:  16.7; xent: 2.8; lr: 0.00200; sents:   48120; bsz: 3736/3794/120; 31123/31608 tok/s;   4848 sec;\n","[2023-06-25 12:34:12,139 INFO] Step 8900/25000; acc: 66.4; ppl:  16.6; xent: 2.8; lr: 0.00199; sents:   47978; bsz: 3733/3803/120; 31268/31851 tok/s;   4896 sec;\n","[2023-06-25 12:34:59,952 INFO] Step 9000/25000; acc: 66.1; ppl:  16.7; xent: 2.8; lr: 0.00198; sents:   46126; bsz: 3736/3802/115; 31255/31804 tok/s;   4943 sec;\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/onmt_train\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/bin/train.py\", line 67, in main\n","    train(opt)\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/bin/train.py\", line 52, in train\n","    train_process(opt, device_id=0)\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/train_single.py\", line 232, in main\n","    trainer.train(\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/trainer.py\", line 334, in train\n","    valid_stats = self.validate(\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/trainer.py\", line 393, in validate\n","    for batch in valid_iter:\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/inputters/inputter.py\", line 33, in __iter__\n","    for tensor_batch in self.iterable:\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/inputters/dynamic_iterator.py\", line 320, in __iter__\n","    for bucket in self._bucketing():\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/inputters/dynamic_iterator.py\", line 257, in _bucketing\n","    for ex in self.mixer:\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/inputters/dynamic_iterator.py\", line 49, in __iter__\n","    yield from iterable\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/inputters/text_corpus.py\", line 233, in __iter__\n","    yield from indexed_corpus\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/inputters/text_corpus.py\", line 207, in _add_index\n","    for i, item in enumerate(stream):\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/inputters/text_corpus.py\", line 191, in _transform\n","    for example in stream:\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/inputters/text_corpus.py\", line 176, in _tokenize\n","    for example in stream:\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/inputters/text_corpus.py\", line 94, in load\n","    with exfile_open(self.src, mode=\"rb\") as fs, exfile_open(\n","  File \"/usr/lib/python3.10/contextlib.py\", line 135, in __enter__\n","    return next(self.gen)\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/inputters/text_corpus.py\", line 35, in exfile_open\n","    _file = codecs.open(filename, *args, **kwargs)\n","  File \"/usr/lib/python3.10/codecs.py\", line 906, in open\n","    file = builtins.open(filename, mode, buffering)\n","OSError: [Errno 107] Transport endpoint is not connected: 'Europarl.en-it.it-filtered.it.subword.dev'\n"]}]},{"cell_type":"code","source":["# Train the NMT model\n","# train 2 layer 1024 hidden size\n","# learning rate 3\n","# warmup steps: 2000\n","!onmt_train -config config_trans.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u-zAdlvelw8v","executionInfo":{"status":"ok","timestamp":1687699749334,"user_tz":-120,"elapsed":2469884,"user":{"displayName":"Manuel Dellabona","userId":"00334919419808458942"}},"outputId":"ed1e2520-771c-4963-9a11-2cc30c1b0d82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2023-06-25 12:48:01,021 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2023-06-25 12:48:01,022 INFO] Parsed 2 corpora from -data.\n","[2023-06-25 12:48:01,022 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n","[2023-06-25 12:48:01,315 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', ',', '▁di', '.', \"'\", '▁e', '▁che']\n","[2023-06-25 12:48:01,315 INFO] The decoder start token is: <s>\n","[2023-06-25 12:48:01,315 INFO] Building model...\n","[2023-06-25 12:48:03,644 INFO] Switching model to float32 for amp/apex_amp\n","[2023-06-25 12:48:03,644 INFO] Non quantized layer compute is fp16\n","[2023-06-25 12:48:04,024 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(49440, 1024, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): ModuleList(\n","      (0-1): 2 x TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=1024, out_features=1024, bias=False)\n","          (linear_values): Linear(in_features=1024, out_features=1024, bias=False)\n","          (linear_query): Linear(in_features=1024, out_features=1024, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=1024, out_features=1024, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=1024, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=1024, bias=False)\n","          (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(48192, 1024, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","    (transformer_layers): ModuleList(\n","      (0-1): 2 x TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=1024, out_features=1024, bias=False)\n","          (linear_values): Linear(in_features=1024, out_features=1024, bias=False)\n","          (linear_query): Linear(in_features=1024, out_features=1024, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=1024, out_features=1024, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=1024, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=1024, bias=False)\n","          (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=1024, out_features=1024, bias=False)\n","          (linear_values): Linear(in_features=1024, out_features=1024, bias=False)\n","          (linear_query): Linear(in_features=1024, out_features=1024, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=1024, out_features=1024, bias=False)\n","        )\n","        (layer_norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (generator): Linear(in_features=1024, out_features=48192, bias=True)\n",")\n","[2023-06-25 12:48:04,026 INFO] encoder: 67414016\n","[2023-06-25 12:48:04,026 INFO] decoder: 123925568\n","[2023-06-25 12:48:04,026 INFO] * number of parameters: 191339584\n","[2023-06-25 12:48:04,026 INFO] Trainable parameters = {'torch.float32': 191339584, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2023-06-25 12:48:04,027 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2023-06-25 12:48:04,027 INFO]  * src vocab size = 49440\n","[2023-06-25 12:48:04,027 INFO]  * tgt vocab size = 48192\n","[2023-06-25 12:48:04,030 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 1\n","[2023-06-25 12:48:04,030 INFO] Starting training on GPU: [0]\n","[2023-06-25 12:48:04,030 INFO] Start training loop and validate every 500 steps...\n","[2023-06-25 12:48:04,031 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=150, tgt_seq_length=192))\n","[2023-06-25 12:49:51,089 INFO] Step 100/25000; acc: 5.8; ppl: 6730.2; xent: 8.8; lr: 0.00011; sents:   47882; bsz: 3737/3798/120; 13963/14191 tok/s;    107 sec;\n","[2023-06-25 12:51:13,806 INFO] Step 200/25000; acc: 17.9; ppl: 663.8; xent: 6.5; lr: 0.00021; sents:   47368; bsz: 3737/3802/118; 18071/18385 tok/s;    190 sec;\n","[2023-06-25 12:52:37,541 INFO] Step 300/25000; acc: 27.4; ppl: 270.1; xent: 5.6; lr: 0.00032; sents:   47686; bsz: 3732/3799/119; 17827/18146 tok/s;    274 sec;\n","[2023-06-25 12:54:01,024 INFO] Step 400/25000; acc: 37.3; ppl: 130.6; xent: 4.9; lr: 0.00042; sents:   49292; bsz: 3720/3792/123; 17823/18168 tok/s;    357 sec;\n","[2023-06-25 12:55:24,782 INFO] Step 500/25000; acc: 45.1; ppl:  74.3; xent: 4.3; lr: 0.00053; sents:   48366; bsz: 3734/3804/121; 17831/18165 tok/s;    441 sec;\n","[2023-06-25 12:55:30,489 INFO] valid stats calculation and sentences rebuilding\n","                           took: 5.706621885299683 s.\n","[2023-06-25 12:55:30,490 INFO] Train perplexity: 410.884\n","[2023-06-25 12:55:30,490 INFO] Train accuracy: 26.7207\n","[2023-06-25 12:55:30,490 INFO] Sentences processed: 240594\n","[2023-06-25 12:55:30,490 INFO] Average bsz: 3732/3799/120\n","[2023-06-25 12:55:30,490 INFO] Validation perplexity: 55.2274\n","[2023-06-25 12:55:30,490 INFO] Validation accuracy: 49.8531\n","[2023-06-25 12:55:30,490 INFO] Model is improving ppl: inf --> 55.2274.\n","[2023-06-25 12:55:30,490 INFO] Model is improving acc: -inf --> 49.8531.\n","[2023-06-25 12:57:29,111 INFO] Step 600/25000; acc: 49.7; ppl:  53.1; xent: 4.0; lr: 0.00063; sents:   49694; bsz: 3728/3797/124; 11995/12218 tok/s;    565 sec;\n","[2023-06-25 12:58:52,927 INFO] Step 700/25000; acc: 52.0; ppl:  44.4; xent: 3.8; lr: 0.00073; sents:   49022; bsz: 3730/3799/123; 17800/18132 tok/s;    649 sec;\n","[2023-06-25 13:00:16,896 INFO] Step 800/25000; acc: 53.4; ppl:  39.7; xent: 3.7; lr: 0.00084; sents:   50093; bsz: 3726/3797/125; 17751/18087 tok/s;    733 sec;\n","[2023-06-25 13:01:40,814 INFO] Step 900/25000; acc: 54.2; ppl:  37.5; xent: 3.6; lr: 0.00094; sents:   48346; bsz: 3730/3798/121; 17779/18105 tok/s;    817 sec;\n","[2023-06-25 13:03:04,752 INFO] Step 1000/25000; acc: 54.6; ppl:  36.2; xent: 3.6; lr: 0.00105; sents:   46359; bsz: 3737/3804/116; 17806/18128 tok/s;    901 sec;\n","[2023-06-25 13:03:04,944 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 13:03:10,501 INFO] valid stats calculation and sentences rebuilding\n","                           took: 5.747967720031738 s.\n","[2023-06-25 13:03:10,502 INFO] Train perplexity: 130.976\n","[2023-06-25 13:03:10,502 INFO] Train accuracy: 39.7525\n","[2023-06-25 13:03:10,502 INFO] Sentences processed: 484108\n","[2023-06-25 13:03:10,502 INFO] Average bsz: 3731/3799/121\n","[2023-06-25 13:03:10,502 INFO] Validation perplexity: 32.126\n","[2023-06-25 13:03:10,502 INFO] Validation accuracy: 56.8975\n","[2023-06-25 13:03:10,503 INFO] Model is improving ppl: 55.2274 --> 32.126.\n","[2023-06-25 13:03:10,503 INFO] Model is improving acc: 49.8531 --> 56.8975.\n","[2023-06-25 13:05:09,473 INFO] Step 1100/25000; acc: 54.8; ppl:  35.5; xent: 3.6; lr: 0.00115; sents:   47237; bsz: 3736/3801/118; 11981/12191 tok/s;   1025 sec;\n","[2023-06-25 13:06:33,699 INFO] Step 1200/25000; acc: 55.1; ppl:  34.8; xent: 3.5; lr: 0.00126; sents:   48904; bsz: 3728/3797/122; 17705/18031 tok/s;   1110 sec;\n","[2023-06-25 13:07:57,616 INFO] Step 1300/25000; acc: 55.0; ppl:  34.7; xent: 3.5; lr: 0.00136; sents:   49244; bsz: 3729/3797/123; 17777/18100 tok/s;   1194 sec;\n","[2023-06-25 13:09:21,382 INFO] Step 1400/25000; acc: 55.0; ppl:  34.5; xent: 3.5; lr: 0.00147; sents:   48245; bsz: 3728/3795/121; 17803/18121 tok/s;   1277 sec;\n","[2023-06-25 13:10:45,068 INFO] Step 1500/25000; acc: 55.2; ppl:  34.0; xent: 3.5; lr: 0.00157; sents:   48642; bsz: 3736/3801/122; 17858/18168 tok/s;   1361 sec;\n","[2023-06-25 13:10:45,252 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 13:10:50,822 INFO] valid stats calculation and sentences rebuilding\n","                           took: 5.7535107135772705 s.\n","[2023-06-25 13:10:50,823 INFO] Train perplexity: 84.1323\n","[2023-06-25 13:10:50,823 INFO] Train accuracy: 44.8381\n","[2023-06-25 13:10:50,823 INFO] Sentences processed: 726380\n","[2023-06-25 13:10:50,823 INFO] Average bsz: 3731/3799/121\n","[2023-06-25 13:10:50,824 INFO] Validation perplexity: 30.48\n","[2023-06-25 13:10:50,824 INFO] Validation accuracy: 57.4645\n","[2023-06-25 13:10:50,824 INFO] Model is improving ppl: 32.126 --> 30.48.\n","[2023-06-25 13:10:50,824 INFO] Model is improving acc: 56.8975 --> 57.4645.\n","[2023-06-25 13:12:14,636 INFO] Step 1600/25000; acc: 55.1; ppl:  34.2; xent: 3.5; lr: 0.00168; sents:   46840; bsz: 3735/3802/117; 16682/16980 tok/s;   1451 sec;\n","[2023-06-25 13:14:11,786 INFO] Step 1700/25000; acc: 55.7; ppl:  32.7; xent: 3.5; lr: 0.00178; sents:   48353; bsz: 3735/3801/121; 12755/12978 tok/s;   1568 sec;\n","[2023-06-25 13:15:35,567 INFO] Step 1800/25000; acc: 56.4; ppl:  31.4; xent: 3.4; lr: 0.00189; sents:   46670; bsz: 3739/3806/117; 17851/18171 tok/s;   1652 sec;\n","[2023-06-25 13:16:59,271 INFO] Step 1900/25000; acc: 57.2; ppl:  29.8; xent: 3.4; lr: 0.00199; sents:   49948; bsz: 3729/3797/125; 17822/18145 tok/s;   1735 sec;\n","[2023-06-25 13:18:23,095 INFO] Step 2000/25000; acc: 57.4; ppl:  29.4; xent: 3.4; lr: 0.00210; sents:   47756; bsz: 3729/3796/119; 17792/18115 tok/s;   1819 sec;\n","[2023-06-25 13:18:23,262 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 13:18:28,836 INFO] valid stats calculation and sentences rebuilding\n","                           took: 5.740450382232666 s.\n","[2023-06-25 13:18:28,837 INFO] Train perplexity: 65.7802\n","[2023-06-25 13:18:28,838 INFO] Train accuracy: 47.7198\n","[2023-06-25 13:18:28,838 INFO] Sentences processed: 965947\n","[2023-06-25 13:18:28,838 INFO] Average bsz: 3732/3799/121\n","[2023-06-25 13:18:28,838 INFO] Validation perplexity: 25.7801\n","[2023-06-25 13:18:28,838 INFO] Validation accuracy: 59.9873\n","[2023-06-25 13:18:28,838 INFO] Model is improving ppl: 30.48 --> 25.7801.\n","[2023-06-25 13:18:28,838 INFO] Model is improving acc: 57.4645 --> 59.9873.\n","[2023-06-25 13:19:52,851 INFO] Step 2100/25000; acc: 58.3; ppl:  27.8; xent: 3.3; lr: 0.00205; sents:   48356; bsz: 3734/3797/121; 16640/16923 tok/s;   1909 sec;\n","[2023-06-25 13:21:54,028 INFO] Step 2200/25000; acc: 58.9; ppl:  26.6; xent: 3.3; lr: 0.00200; sents:   46175; bsz: 3744/3803/115; 12359/12555 tok/s;   2030 sec;\n","[2023-06-25 13:23:18,023 INFO] Step 2300/25000; acc: 59.9; ppl:  25.3; xent: 3.2; lr: 0.00195; sents:   49378; bsz: 3729/3794/123; 17759/18067 tok/s;   2114 sec;\n","[2023-06-25 13:24:42,030 INFO] Step 2400/25000; acc: 60.2; ppl:  24.6; xent: 3.2; lr: 0.00191; sents:   48450; bsz: 3733/3799/121; 17774/18087 tok/s;   2198 sec;\n","[2023-06-25 13:26:06,205 INFO] Step 2500/25000; acc: 60.4; ppl:  24.0; xent: 3.2; lr: 0.00187; sents:   45387; bsz: 3746/3802/113; 17799/18069 tok/s;   2282 sec;\n","[2023-06-25 13:26:06,401 INFO] * Transform statistics for valid(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=1)\n","\n","[2023-06-25 13:26:11,960 INFO] valid stats calculation and sentences rebuilding\n","                           took: 5.753986597061157 s.\n","[2023-06-25 13:26:11,961 INFO] Train perplexity: 54.4763\n","[2023-06-25 13:26:11,961 INFO] Train accuracy: 50.0878\n","[2023-06-25 13:26:11,961 INFO] Sentences processed: 1.20369e+06\n","[2023-06-25 13:26:11,961 INFO] Average bsz: 3733/3799/120\n","[2023-06-25 13:26:11,961 INFO] Validation perplexity: 21.4756\n","[2023-06-25 13:26:11,961 INFO] Validation accuracy: 62.774\n","[2023-06-25 13:26:11,961 INFO] Model is improving ppl: 25.7801 --> 21.4756.\n","[2023-06-25 13:26:11,961 INFO] Model is improving acc: 59.9873 --> 62.774.\n","[2023-06-25 13:27:35,668 INFO] Step 2600/25000; acc: 61.3; ppl:  23.1; xent: 3.1; lr: 0.00184; sents:   50529; bsz: 3720/3794/126; 16633/16966 tok/s;   2372 sec;\n","[2023-06-25 13:28:59,583 INFO] Step 2700/25000; acc: 61.6; ppl:  22.6; xent: 3.1; lr: 0.00180; sents:   48911; bsz: 3729/3803/122; 17773/18128 tok/s;   2456 sec;\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/onmt_train\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/bin/train.py\", line 67, in main\n","    train(opt)\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/bin/train.py\", line 52, in train\n","    train_process(opt, device_id=0)\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/train_single.py\", line 232, in main\n","    trainer.train(\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/trainer.py\", line 318, in train\n","    self._gradient_accumulation(\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/trainer.py\", line 509, in _gradient_accumulation\n","    loss, batch_stats = self.train_loss(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/utils/loss.py\", line 361, in forward\n","    stats = self._stats(n_sents, loss.sum().item(), scores, flat_tgt)\n","KeyboardInterrupt\n","^C\n"]}]}]}